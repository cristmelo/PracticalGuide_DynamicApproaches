{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run auxTensor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a new dataframe without containing the last release...\n",
      "... DONE!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountClassCoupled</th>\n",
       "      <th>CountDeclMethod</th>\n",
       "      <th>CountDeclMethodAll</th>\n",
       "      <th>CountClassDerived</th>\n",
       "      <th>CountLineCode</th>\n",
       "      <th>SumCyclomatic</th>\n",
       "      <th>PercentLackOfCohesion</th>\n",
       "      <th>MaxInheritanceTree</th>\n",
       "      <th>Path</th>\n",
       "      <th>will_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.CleanupHelper.CleanupHelp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.Util.Util.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.bulkloader.CassandraBulkL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.bulkloader.CassandraBulkL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.bulkloader.CassandraBulkL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.cli.CliClient.CliClient.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.cli.CliCompiler.CliCompil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.cli.CliCompiler.ANTLRNoCa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.cli.CliMain.CliMain.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.cli.CliOptions.CliOptions...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.cli.CliSessionState.CliSe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.cli.CliUtils.CliUtils.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.client.RingCache.RingCach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.client.TestRingCache.Test...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.concurrent.AIOExecutorSer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.concurrent.Context.Contex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.concurrent.DebuggableSche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.concurrent.DebuggableThre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.concurrent.MultiThreadedS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.concurrent.SingleThreaded...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.concurrent.StageManager.S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.concurrent.ThreadFactoryI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.concurrent.ThreadLocalCon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.config.CFMetaData.CFMetaD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.config.DatabaseDescriptor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.config.DatabaseDescriptor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.config.DatabaseDescriptor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.db.BinaryMemtable.BinaryM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.db.BinaryVerbHandler.Bina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.db.BootstrapTest.Bootstra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127236</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.MemtableClea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127237</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.MemtableClea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127238</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.MemtableClea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127239</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.MemtablePool...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127240</th>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.MemtablePool...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127241</th>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.NativeAlloca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127242</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.NativeAlloca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127243</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.NativeAlloca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127244</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.NativeAlloca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127245</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.NativeAlloca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127246</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.NativeAlloca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127247</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.NativeAlloca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127248</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.NativePool.N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127249</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.SlabAllocato...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.SlabAllocato...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127251</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.cassandra.utils.memory.SlabPool.Sla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127252</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.obs.BitUtil.BitUtil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127253</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.obs.OffHeapBitSet.O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127254</th>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.obs.OpenBitSet.Open...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127255</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.progress.ProgressEv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127256</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.progress.ProgressEv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127257</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.progress.jmx.JMXNot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127258</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.progress.jmx.JMXPro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127259</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.progress.jmx.Legacy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127260</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.cassandra.utils.progress.jmx.Legacy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127261</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>org.apache.cassandra.utils.vint.EncodedDataInp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127262</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>org.apache.cassandra.utils.vint.EncodedDataOut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127263</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.pig.test.MiniCluster.MiniCluster.java</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127264</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.pig.test.MiniGenericCluster.MiniGen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127265</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.pig.test.WindowsLocalFileSystem.Win...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127266 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CountClassCoupled  CountDeclMethod  CountDeclMethodAll  \\\n",
       "0                     1.0              1.0                 1.0   \n",
       "1                     3.0              3.0                 3.0   \n",
       "2                    13.0              5.0                 5.0   \n",
       "3                     0.0              1.0                 1.0   \n",
       "4                     9.0              3.0                 3.0   \n",
       "5                    15.0             10.0                10.0   \n",
       "6                     2.0              6.0                 6.0   \n",
       "7                     0.0              2.0                 2.0   \n",
       "8                     5.0              6.0                 6.0   \n",
       "9                     1.0              2.0                 2.0   \n",
       "10                    0.0              1.0                 1.0   \n",
       "11                    0.0              1.0                 1.0   \n",
       "12                   11.0              3.0                 3.0   \n",
       "13                    7.0              2.0                 2.0   \n",
       "14                    0.0             14.0                14.0   \n",
       "15                    0.0              4.0                 4.0   \n",
       "16                    3.0              2.0                 2.0   \n",
       "17                    3.0              4.0                 4.0   \n",
       "18                    2.0             11.0                11.0   \n",
       "19                    1.0             11.0                11.0   \n",
       "20                    1.0              7.0                 7.0   \n",
       "21                    0.0              2.0                 2.0   \n",
       "22                    1.0              2.0                 2.0   \n",
       "23                    1.0              1.0                 1.0   \n",
       "24                   16.0             61.0                61.0   \n",
       "25                    0.0              1.0                 1.0   \n",
       "26                    1.0              1.0                 1.0   \n",
       "27                    7.0              8.0                 8.0   \n",
       "28                    7.0              1.0                 1.0   \n",
       "29                   11.0              3.0                 3.0   \n",
       "...                   ...              ...                 ...   \n",
       "127236                1.0              3.0                 8.0   \n",
       "127237                4.0              3.0                 3.0   \n",
       "127238                3.0              1.0                 1.0   \n",
       "127239                5.0              6.0                 6.0   \n",
       "127240                5.0             16.0                16.0   \n",
       "127241               20.0             11.0                23.0   \n",
       "127242                1.0              2.0                 2.0   \n",
       "127243                0.0              3.0                 3.0   \n",
       "127244                4.0              1.0                 1.0   \n",
       "127245                1.0              1.0                 1.0   \n",
       "127246                2.0              1.0                 1.0   \n",
       "127247                4.0              1.0                 1.0   \n",
       "127248                1.0              3.0                 9.0   \n",
       "127249                7.0              7.0                27.0   \n",
       "127250                0.0              3.0                 3.0   \n",
       "127251                3.0              3.0                 9.0   \n",
       "127252                0.0             14.0                14.0   \n",
       "127253                3.0             16.0                16.0   \n",
       "127254                2.0             31.0                31.0   \n",
       "127255                1.0              8.0                 8.0   \n",
       "127256                2.0              3.0                 3.0   \n",
       "127257                2.0              5.0                 5.0   \n",
       "127258                1.0              2.0                 2.0   \n",
       "127259                3.0              5.0                 5.0   \n",
       "127260                9.0              5.0                 5.0   \n",
       "127261                0.0             14.0                32.0   \n",
       "127262                0.0              8.0                32.0   \n",
       "127263                2.0              3.0                16.0   \n",
       "127264                1.0             13.0                13.0   \n",
       "127265                0.0              3.0                 3.0   \n",
       "\n",
       "        CountClassDerived  CountLineCode  SumCyclomatic  \\\n",
       "0                    12.0           48.0            8.0   \n",
       "1                     0.0           18.0            0.0   \n",
       "2                     0.0          162.0           35.0   \n",
       "3                     0.0            6.0           17.0   \n",
       "4                     0.0           68.0           18.0   \n",
       "5                     0.0          220.0           17.0   \n",
       "6                     0.0           64.0           53.0   \n",
       "7                     0.0           20.0            0.0   \n",
       "8                     0.0           88.0           26.0   \n",
       "9                     0.0           49.0           63.0   \n",
       "10                    0.0           13.0           69.0   \n",
       "11                    0.0           36.0           14.0   \n",
       "12                    0.0           56.0           39.0   \n",
       "13                    0.0           39.0           69.0   \n",
       "14                    0.0           64.0           48.0   \n",
       "15                    0.0           20.0            0.0   \n",
       "16                    0.0           35.0           74.0   \n",
       "17                    0.0           65.0           45.0   \n",
       "18                    0.0           50.0           44.0   \n",
       "19                    0.0           49.0           53.0   \n",
       "20                    0.0           43.0           28.0   \n",
       "21                    0.0           18.0           22.0   \n",
       "22                    0.0           12.0           75.0   \n",
       "23                    0.0           30.0           90.0   \n",
       "24                    0.0          763.0           15.0   \n",
       "25                    0.0            7.0            0.0   \n",
       "26                    0.0            8.0            0.0   \n",
       "27                    0.0          106.0           35.0   \n",
       "28                    0.0           28.0           68.0   \n",
       "29                    0.0           46.0           13.0   \n",
       "...                   ...            ...            ...   \n",
       "127236                0.0           54.0            3.0   \n",
       "127237                0.0           31.0            5.0   \n",
       "127238                0.0            5.0            1.0   \n",
       "127239                5.0          145.0            6.0   \n",
       "127240                0.0          111.0           30.0   \n",
       "127241                0.0          146.0           21.0   \n",
       "127242                0.0           19.0            4.0   \n",
       "127243                0.0           33.0            6.0   \n",
       "127244                0.0           87.0            1.0   \n",
       "127245                0.0           17.0            3.0   \n",
       "127246                0.0            7.0            1.0   \n",
       "127247                0.0           39.0            3.0   \n",
       "127248                0.0           17.0            3.0   \n",
       "127249                0.0          111.0           20.0   \n",
       "127250                0.0           31.0            6.0   \n",
       "127251                0.0           17.0            3.0   \n",
       "127252                0.0          552.0           52.0   \n",
       "127253                0.0          132.0           23.0   \n",
       "127254                0.0          243.0           65.0   \n",
       "127255                0.0           42.0            9.0   \n",
       "127256                1.0           21.0            4.0   \n",
       "127257                2.0           37.0            9.0   \n",
       "127258                0.0           24.0            2.0   \n",
       "127259                0.0           64.0           13.0   \n",
       "127260                0.0           70.0            5.0   \n",
       "127261                0.0           79.0           19.0   \n",
       "127262                0.0           60.0           13.0   \n",
       "127263                0.0           46.0            6.0   \n",
       "127264                1.0           61.0           16.0   \n",
       "127265                0.0           27.0            4.0   \n",
       "\n",
       "        PercentLackOfCohesion  MaxInheritanceTree  \\\n",
       "0                         0.0                 1.0   \n",
       "1                         0.0                 1.0   \n",
       "2                         0.0                 1.0   \n",
       "3                       100.0                 2.0   \n",
       "4                        55.0                 2.0   \n",
       "5                        25.0                 1.0   \n",
       "6                         0.0                 1.0   \n",
       "7                         0.0                 2.0   \n",
       "8                        54.0                 1.0   \n",
       "9                        50.0                 1.0   \n",
       "10                       50.0                 1.0   \n",
       "11                        0.0                 1.0   \n",
       "12                       44.0                 1.0   \n",
       "13                       25.0                 1.0   \n",
       "14                        7.0                 1.0   \n",
       "15                        0.0                 1.0   \n",
       "16                       50.0                 2.0   \n",
       "17                       75.0                 2.0   \n",
       "18                       59.0                 1.0   \n",
       "19                       59.0                 1.0   \n",
       "20                       28.0                 1.0   \n",
       "21                       16.0                 1.0   \n",
       "22                        0.0                 1.0   \n",
       "23                        7.0                 1.0   \n",
       "24                       98.0                 1.0   \n",
       "25                        0.0                 2.0   \n",
       "26                        0.0                 1.0   \n",
       "27                       70.0                 1.0   \n",
       "28                        0.0                 1.0   \n",
       "29                        0.0                 1.0   \n",
       "...                       ...                 ...   \n",
       "127236                   33.0                 2.0   \n",
       "127237                   44.0                 1.0   \n",
       "127238                    0.0                 2.0   \n",
       "127239                   75.0                 1.0   \n",
       "127240                   81.0                 1.0   \n",
       "127241                   77.0                 2.0   \n",
       "127242                    0.0                 1.0   \n",
       "127243                   25.0                 1.0   \n",
       "127244                    0.0                 1.0   \n",
       "127245                    0.0                 2.0   \n",
       "127246                    0.0                 2.0   \n",
       "127247                    0.0                 2.0   \n",
       "127248                    0.0                 2.0   \n",
       "127249                   71.0                 3.0   \n",
       "127250                   22.0                 1.0   \n",
       "127251                    0.0                 2.0   \n",
       "127252                    0.0                 1.0   \n",
       "127253                   12.0                 1.0   \n",
       "127254                   70.0                 1.0   \n",
       "127255                   68.0                 1.0   \n",
       "127256                    0.0                 1.0   \n",
       "127257                    0.0                 1.0   \n",
       "127258                   25.0                 1.0   \n",
       "127259                   66.0                 1.0   \n",
       "127260                    0.0                 1.0   \n",
       "127261                   71.0                 3.0   \n",
       "127262                   50.0                 4.0   \n",
       "127263                   33.0                 2.0   \n",
       "127264                   79.0                 1.0   \n",
       "127265                   66.0                 2.0   \n",
       "\n",
       "                                                     Path  will_change  \n",
       "0       org.apache.cassandra.CleanupHelper.CleanupHelp...            0  \n",
       "1                     org.apache.cassandra.Util.Util.java            0  \n",
       "2       org.apache.cassandra.bulkloader.CassandraBulkL...            0  \n",
       "3       org.apache.cassandra.bulkloader.CassandraBulkL...            0  \n",
       "4       org.apache.cassandra.bulkloader.CassandraBulkL...            0  \n",
       "5       org.apache.cassandra.cli.CliClient.CliClient.java            0  \n",
       "6       org.apache.cassandra.cli.CliCompiler.CliCompil...            0  \n",
       "7       org.apache.cassandra.cli.CliCompiler.ANTLRNoCa...            0  \n",
       "8           org.apache.cassandra.cli.CliMain.CliMain.java            0  \n",
       "9       org.apache.cassandra.cli.CliOptions.CliOptions...            0  \n",
       "10      org.apache.cassandra.cli.CliSessionState.CliSe...            0  \n",
       "11        org.apache.cassandra.cli.CliUtils.CliUtils.java            0  \n",
       "12      org.apache.cassandra.client.RingCache.RingCach...            0  \n",
       "13      org.apache.cassandra.client.TestRingCache.Test...            0  \n",
       "14      org.apache.cassandra.concurrent.AIOExecutorSer...            0  \n",
       "15      org.apache.cassandra.concurrent.Context.Contex...            0  \n",
       "16      org.apache.cassandra.concurrent.DebuggableSche...            0  \n",
       "17      org.apache.cassandra.concurrent.DebuggableThre...            0  \n",
       "18      org.apache.cassandra.concurrent.MultiThreadedS...            0  \n",
       "19      org.apache.cassandra.concurrent.SingleThreaded...            0  \n",
       "20      org.apache.cassandra.concurrent.StageManager.S...            0  \n",
       "21      org.apache.cassandra.concurrent.ThreadFactoryI...            0  \n",
       "22      org.apache.cassandra.concurrent.ThreadLocalCon...            0  \n",
       "23      org.apache.cassandra.config.CFMetaData.CFMetaD...            0  \n",
       "24      org.apache.cassandra.config.DatabaseDescriptor...            0  \n",
       "25      org.apache.cassandra.config.DatabaseDescriptor...            0  \n",
       "26      org.apache.cassandra.config.DatabaseDescriptor...            0  \n",
       "27      org.apache.cassandra.db.BinaryMemtable.BinaryM...            0  \n",
       "28      org.apache.cassandra.db.BinaryVerbHandler.Bina...            0  \n",
       "29      org.apache.cassandra.db.BootstrapTest.Bootstra...            0  \n",
       "...                                                   ...          ...  \n",
       "127236  org.apache.cassandra.utils.memory.MemtableClea...            1  \n",
       "127237  org.apache.cassandra.utils.memory.MemtableClea...            0  \n",
       "127238  org.apache.cassandra.utils.memory.MemtableClea...            0  \n",
       "127239  org.apache.cassandra.utils.memory.MemtablePool...            1  \n",
       "127240  org.apache.cassandra.utils.memory.MemtablePool...            0  \n",
       "127241  org.apache.cassandra.utils.memory.NativeAlloca...            1  \n",
       "127242  org.apache.cassandra.utils.memory.NativeAlloca...            0  \n",
       "127243  org.apache.cassandra.utils.memory.NativeAlloca...            0  \n",
       "127244  org.apache.cassandra.utils.memory.NativeAlloca...            0  \n",
       "127245  org.apache.cassandra.utils.memory.NativeAlloca...            0  \n",
       "127246  org.apache.cassandra.utils.memory.NativeAlloca...            0  \n",
       "127247  org.apache.cassandra.utils.memory.NativeAlloca...            0  \n",
       "127248  org.apache.cassandra.utils.memory.NativePool.N...            0  \n",
       "127249  org.apache.cassandra.utils.memory.SlabAllocato...            0  \n",
       "127250  org.apache.cassandra.utils.memory.SlabAllocato...            0  \n",
       "127251  org.apache.cassandra.utils.memory.SlabPool.Sla...            0  \n",
       "127252  org.apache.cassandra.utils.obs.BitUtil.BitUtil...            0  \n",
       "127253  org.apache.cassandra.utils.obs.OffHeapBitSet.O...            1  \n",
       "127254  org.apache.cassandra.utils.obs.OpenBitSet.Open...            0  \n",
       "127255  org.apache.cassandra.utils.progress.ProgressEv...            0  \n",
       "127256  org.apache.cassandra.utils.progress.ProgressEv...            0  \n",
       "127257  org.apache.cassandra.utils.progress.jmx.JMXNot...            0  \n",
       "127258  org.apache.cassandra.utils.progress.jmx.JMXPro...            0  \n",
       "127259  org.apache.cassandra.utils.progress.jmx.Legacy...            0  \n",
       "127260  org.apache.cassandra.utils.progress.jmx.Legacy...            0  \n",
       "127261  org.apache.cassandra.utils.vint.EncodedDataInp...            1  \n",
       "127262  org.apache.cassandra.utils.vint.EncodedDataOut...            0  \n",
       "127263   org.apache.pig.test.MiniCluster.MiniCluster.java            1  \n",
       "127264  org.apache.pig.test.MiniGenericCluster.MiniGen...            0  \n",
       "127265  org.apache.pig.test.WindowsLocalFileSystem.Win...            0  \n",
       "\n",
       "[127266 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_releases_df = pd.read_csv('all_releases.csv')\n",
    "\n",
    "#all_releases_df.head()\n",
    "\n",
    "print(\"Generating a new dataframe without containing the last release...\")\n",
    "df = all_releases_df[all_releases_df['release'] != all_releases_df['release'].max()]\n",
    "print(\"... DONE!\")\n",
    "\n",
    "df.drop(columns=['class_frequency', 'number_of_changes', 'release', 'Name', 'Kind', 'File'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (118733, 8, 2)\n",
      "tensor input y: (118733, 2)\n",
      "proportion of y labels: (array([0, 1]), array([22043, 96690]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (83113, 2, 8)\n",
      "Tensor y train: (83113, 2)\n",
      "Tensor X test: (35620, 2, 8)\n",
      "Tensor y test: (35620, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (2, 8) 2\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-1-fb283a009ca9>:2: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 66490 samples, validate on 16623 samples\n",
      "Epoch 1/20\n",
      "66490/66490 [==============================] - 3s 52us/step - loss: 0.1700 - acc: 0.6943 - auc: 0.7814 - f1: 0.6943 - val_loss: 0.1618 - val_acc: 0.6793 - val_auc: 0.8121 - val_f1: 0.6793\n",
      "Epoch 2/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.1569 - acc: 0.7180 - auc: 0.8190 - f1: 0.7180 - val_loss: 0.1489 - val_acc: 0.7484 - val_auc: 0.8414 - val_f1: 0.7484\n",
      "Epoch 3/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.1444 - acc: 0.7506 - auc: 0.8514 - f1: 0.7506 - val_loss: 0.1295 - val_acc: 0.7979 - val_auc: 0.8848 - val_f1: 0.7979\n",
      "Epoch 4/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.1221 - acc: 0.7929 - auc: 0.8967 - f1: 0.7929 - val_loss: 0.1125 - val_acc: 0.8649 - val_auc: 0.9241 - val_f1: 0.8649\n",
      "Epoch 5/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.1090 - acc: 0.8202 - auc: 0.9190 - f1: 0.8202 - val_loss: 0.0991 - val_acc: 0.8550 - val_auc: 0.9350 - val_f1: 0.8550\n",
      "Epoch 6/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.1025 - acc: 0.8288 - auc: 0.9287 - f1: 0.8288 - val_loss: 0.0968 - val_acc: 0.8466 - val_auc: 0.9378 - val_f1: 0.8466\n",
      "Epoch 7/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0962 - acc: 0.8438 - auc: 0.9367 - f1: 0.8438 - val_loss: 0.0874 - val_acc: 0.8670 - val_auc: 0.9489 - val_f1: 0.8670\n",
      "Epoch 8/20\n",
      "66490/66490 [==============================] - 3s 45us/step - loss: 0.0911 - acc: 0.8506 - auc: 0.9433 - f1: 0.8506 - val_loss: 0.0823 - val_acc: 0.8873 - val_auc: 0.9555 - val_f1: 0.8873\n",
      "Epoch 9/20\n",
      "66490/66490 [==============================] - 3s 45us/step - loss: 0.0864 - acc: 0.8596 - auc: 0.9485 - f1: 0.8596 - val_loss: 0.0768 - val_acc: 0.8919 - val_auc: 0.9612 - val_f1: 0.8919\n",
      "Epoch 10/20\n",
      "66490/66490 [==============================] - 3s 45us/step - loss: 0.0920 - acc: 0.8511 - auc: 0.9421 - f1: 0.8511 - val_loss: 0.0773 - val_acc: 0.8900 - val_auc: 0.9607 - val_f1: 0.8900\n",
      "Epoch 11/20\n",
      "66490/66490 [==============================] - 3s 45us/step - loss: 0.0837 - acc: 0.8631 - auc: 0.9517 - f1: 0.8631 - val_loss: 0.0710 - val_acc: 0.8941 - val_auc: 0.9656 - val_f1: 0.8941\n",
      "Epoch 12/20\n",
      "66490/66490 [==============================] - 3s 45us/step - loss: 0.0808 - acc: 0.8682 - auc: 0.9547 - f1: 0.8682 - val_loss: 0.0679 - val_acc: 0.8910 - val_auc: 0.9678 - val_f1: 0.8910\n",
      "Epoch 13/20\n",
      "66490/66490 [==============================] - 3s 45us/step - loss: 0.0806 - acc: 0.8685 - auc: 0.9550 - f1: 0.8685 - val_loss: 0.0696 - val_acc: 0.9039 - val_auc: 0.9679 - val_f1: 0.9039\n",
      "Epoch 14/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0783 - acc: 0.8737 - auc: 0.9577 - f1: 0.8737 - val_loss: 0.0687 - val_acc: 0.8988 - val_auc: 0.9676 - val_f1: 0.8988\n",
      "Epoch 15/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0773 - acc: 0.8756 - auc: 0.9585 - f1: 0.8756 - val_loss: 0.0681 - val_acc: 0.9032 - val_auc: 0.9686 - val_f1: 0.9032\n",
      "Epoch 16/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0766 - acc: 0.8747 - auc: 0.9596 - f1: 0.8747 - val_loss: 0.0651 - val_acc: 0.9009 - val_auc: 0.9704 - val_f1: 0.9009\n",
      "Epoch 17/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0772 - acc: 0.8765 - auc: 0.9587 - f1: 0.8765 - val_loss: 0.0653 - val_acc: 0.9039 - val_auc: 0.9703 - val_f1: 0.9039\n",
      "Epoch 18/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0860 - acc: 0.8654 - auc: 0.9501 - f1: 0.8654 - val_loss: 0.0646 - val_acc: 0.9091 - val_auc: 0.9712 - val_f1: 0.9091\n",
      "Epoch 19/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0729 - acc: 0.8824 - auc: 0.9631 - f1: 0.8824 - val_loss: 0.0664 - val_acc: 0.8968 - val_auc: 0.9693 - val_f1: 0.8968\n",
      "Epoch 20/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0752 - acc: 0.8780 - auc: 0.9610 - f1: 0.8780 - val_loss: 0.0632 - val_acc: 0.9082 - val_auc: 0.9723 - val_f1: 0.9082\n",
      "[[ 2827   255]\n",
      " [ 1271 12270]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79      3082\n",
      "           1       0.98      0.91      0.94     13541\n",
      "\n",
      "    accuracy                           0.91     16623\n",
      "   macro avg       0.83      0.91      0.86     16623\n",
      "weighted avg       0.93      0.91      0.91     16623\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (2, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66490 samples, validate on 16623 samples\n",
      "Epoch 1/20\n",
      "66490/66490 [==============================] - 4s 55us/step - loss: 0.1700 - acc: 0.6948 - auc: 0.7809 - f1: 0.6948 - val_loss: 0.1558 - val_acc: 0.7260 - val_auc: 0.8212 - val_f1: 0.7260\n",
      "Epoch 2/20\n",
      "66490/66490 [==============================] - 3s 42us/step - loss: 0.1571 - acc: 0.7200 - auc: 0.8199 - f1: 0.7200 - val_loss: 0.1463 - val_acc: 0.7903 - val_auc: 0.8520 - val_f1: 0.7903\n",
      "Epoch 3/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.1466 - acc: 0.7477 - auc: 0.8479 - f1: 0.7477 - val_loss: 0.1318 - val_acc: 0.8073 - val_auc: 0.8812 - val_f1: 0.8073\n",
      "Epoch 4/20\n",
      "66490/66490 [==============================] - 3s 42us/step - loss: 0.1304 - acc: 0.7853 - auc: 0.8823 - f1: 0.7853 - val_loss: 0.1110 - val_acc: 0.8414 - val_auc: 0.9169 - val_f1: 0.8414\n",
      "Epoch 5/20\n",
      "66490/66490 [==============================] - 3s 42us/step - loss: 0.1139 - acc: 0.8157 - auc: 0.9116 - f1: 0.8157 - val_loss: 0.0958 - val_acc: 0.8561 - val_auc: 0.9375 - val_f1: 0.8561\n",
      "Epoch 6/20\n",
      "66490/66490 [==============================] - 3s 42us/step - loss: 0.1047 - acc: 0.8298 - auc: 0.9255 - f1: 0.8298 - val_loss: 0.0926 - val_acc: 0.8438 - val_auc: 0.9404 - val_f1: 0.8438\n",
      "Epoch 7/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.1013 - acc: 0.8359 - auc: 0.9298 - f1: 0.8359 - val_loss: 0.0853 - val_acc: 0.8610 - val_auc: 0.9500 - val_f1: 0.8610\n",
      "Epoch 8/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.0929 - acc: 0.8516 - auc: 0.9411 - f1: 0.8516 - val_loss: 0.0842 - val_acc: 0.8832 - val_auc: 0.9512 - val_f1: 0.8832\n",
      "Epoch 9/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0906 - acc: 0.8557 - auc: 0.9441 - f1: 0.8557 - val_loss: 0.0780 - val_acc: 0.8953 - val_auc: 0.9586 - val_f1: 0.8953\n",
      "Epoch 10/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.0829 - acc: 0.8660 - auc: 0.9528 - f1: 0.8660 - val_loss: 0.0829 - val_acc: 0.8725 - val_auc: 0.9525 - val_f1: 0.8725\n",
      "Epoch 11/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.0906 - acc: 0.8586 - auc: 0.9445 - f1: 0.8586 - val_loss: 0.0792 - val_acc: 0.8840 - val_auc: 0.9565 - val_f1: 0.8840\n",
      "Epoch 12/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.0800 - acc: 0.8735 - auc: 0.9558 - f1: 0.8735 - val_loss: 0.0761 - val_acc: 0.8845 - val_auc: 0.9597 - val_f1: 0.8845\n",
      "Epoch 13/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.0787 - acc: 0.8757 - auc: 0.9571 - f1: 0.8757 - val_loss: 0.0704 - val_acc: 0.8844 - val_auc: 0.9654 - val_f1: 0.8844\n",
      "Epoch 14/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.0795 - acc: 0.8756 - auc: 0.9571 - f1: 0.8756 - val_loss: 0.0715 - val_acc: 0.9011 - val_auc: 0.9648 - val_f1: 0.9011\n",
      "Epoch 15/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.0759 - acc: 0.8808 - auc: 0.9601 - f1: 0.8808 - val_loss: 0.0835 - val_acc: 0.9010 - val_auc: 0.9572 - val_f1: 0.9010\n",
      "Epoch 16/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0761 - acc: 0.8791 - auc: 0.9603 - f1: 0.8791 - val_loss: 0.0718 - val_acc: 0.8952 - val_auc: 0.9644 - val_f1: 0.8952\n",
      "Epoch 17/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0747 - acc: 0.8823 - auc: 0.9620 - f1: 0.8823 - val_loss: 0.0665 - val_acc: 0.8988 - val_auc: 0.9686 - val_f1: 0.8988\n",
      "Epoch 18/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.0698 - acc: 0.8897 - auc: 0.9661 - f1: 0.8897 - val_loss: 0.0691 - val_acc: 0.8909 - val_auc: 0.9671 - val_f1: 0.8909\n",
      "Epoch 19/20\n",
      "66490/66490 [==============================] - 3s 44us/step - loss: 0.0740 - acc: 0.8827 - auc: 0.9622 - f1: 0.8827 - val_loss: 0.0664 - val_acc: 0.8966 - val_auc: 0.9688 - val_f1: 0.8966\n",
      "Epoch 20/20\n",
      "66490/66490 [==============================] - 3s 43us/step - loss: 0.0703 - acc: 0.8863 - auc: 0.9657 - f1: 0.8863 - val_loss: 0.0725 - val_acc: 0.9114 - val_auc: 0.9659 - val_f1: 0.9114\n",
      "[[ 2675   407]\n",
      " [ 1065 12476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.78      3082\n",
      "           1       0.97      0.92      0.94     13541\n",
      "\n",
      "    accuracy                           0.91     16623\n",
      "   macro avg       0.84      0.89      0.86     16623\n",
      "weighted avg       0.92      0.91      0.91     16623\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (2, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 66490 samples, validate on 16623 samples\n",
      "Epoch 1/20\n",
      "66490/66490 [==============================] - 4s 59us/step - loss: 0.1703 - acc: 0.6976 - auc: 0.7822 - f1: 0.6976 - val_loss: 0.1597 - val_acc: 0.6996 - val_auc: 0.8107 - val_f1: 0.6996\n",
      "Epoch 2/20\n",
      "66490/66490 [==============================] - 3s 46us/step - loss: 0.1585 - acc: 0.7161 - auc: 0.8158 - f1: 0.7161 - val_loss: 0.1523 - val_acc: 0.7019 - val_auc: 0.8306 - val_f1: 0.7019\n",
      "Epoch 3/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.1480 - acc: 0.7411 - auc: 0.8432 - f1: 0.7411 - val_loss: 0.1365 - val_acc: 0.7465 - val_auc: 0.8699 - val_f1: 0.7465\n",
      "Epoch 4/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.1273 - acc: 0.7837 - auc: 0.8873 - f1: 0.7837 - val_loss: 0.1217 - val_acc: 0.8321 - val_auc: 0.9074 - val_f1: 0.8321\n",
      "Epoch 5/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.1130 - acc: 0.8108 - auc: 0.9125 - f1: 0.8108 - val_loss: 0.1026 - val_acc: 0.8449 - val_auc: 0.9280 - val_f1: 0.8449\n",
      "Epoch 6/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.1051 - acc: 0.8281 - auc: 0.9239 - f1: 0.8281 - val_loss: 0.0915 - val_acc: 0.8652 - val_auc: 0.9418 - val_f1: 0.8652\n",
      "Epoch 7/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.1017 - acc: 0.8318 - auc: 0.9286 - f1: 0.8318 - val_loss: 0.1041 - val_acc: 0.8340 - val_auc: 0.9252 - val_f1: 0.8340\n",
      "Epoch 8/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.0923 - acc: 0.8481 - auc: 0.9411 - f1: 0.8481 - val_loss: 0.1092 - val_acc: 0.8200 - val_auc: 0.9210 - val_f1: 0.8200\n",
      "Epoch 9/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.0917 - acc: 0.8521 - auc: 0.9423 - f1: 0.8521 - val_loss: 0.0865 - val_acc: 0.8796 - val_auc: 0.9518 - val_f1: 0.8796\n",
      "Epoch 10/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.0917 - acc: 0.8525 - auc: 0.9430 - f1: 0.8525 - val_loss: 0.0989 - val_acc: 0.8624 - val_auc: 0.9350 - val_f1: 0.8624\n",
      "Epoch 11/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.0838 - acc: 0.8662 - auc: 0.9513 - f1: 0.8662 - val_loss: 0.0987 - val_acc: 0.8254 - val_auc: 0.9367 - val_f1: 0.8254\n",
      "Epoch 12/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.0812 - acc: 0.8692 - auc: 0.9543 - f1: 0.8692 - val_loss: 0.0793 - val_acc: 0.8906 - val_auc: 0.9586 - val_f1: 0.8906\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66490/66490 [==============================] - 3s 46us/step - loss: 0.0796 - acc: 0.8716 - auc: 0.9559 - f1: 0.8716 - val_loss: 0.0731 - val_acc: 0.8896 - val_auc: 0.9632 - val_f1: 0.8896\n",
      "Epoch 14/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.0805 - acc: 0.8696 - auc: 0.9553 - f1: 0.8696 - val_loss: 0.0751 - val_acc: 0.8841 - val_auc: 0.9603 - val_f1: 0.8841\n",
      "Epoch 15/20\n",
      "66490/66490 [==============================] - 3s 46us/step - loss: 0.0820 - acc: 0.8711 - auc: 0.9538 - f1: 0.8711 - val_loss: 0.0726 - val_acc: 0.8930 - val_auc: 0.9629 - val_f1: 0.8930\n",
      "Epoch 16/20\n",
      "66490/66490 [==============================] - 3s 47us/step - loss: 0.0739 - acc: 0.8815 - auc: 0.9617 - f1: 0.8815 - val_loss: 0.0772 - val_acc: 0.8791 - val_auc: 0.9599 - val_f1: 0.8791\n",
      "Epoch 17/20\n",
      "66490/66490 [==============================] - 3s 46us/step - loss: 0.0729 - acc: 0.8823 - auc: 0.9629 - f1: 0.8823 - val_loss: 0.0745 - val_acc: 0.8747 - val_auc: 0.9621 - val_f1: 0.8747\n",
      "Epoch 18/20\n",
      "66490/66490 [==============================] - 3s 46us/step - loss: 0.0755 - acc: 0.8770 - auc: 0.9601 - f1: 0.8770 - val_loss: 0.0711 - val_acc: 0.8880 - val_auc: 0.9643 - val_f1: 0.8880\n",
      "Epoch 19/20\n",
      "66490/66490 [==============================] - 3s 46us/step - loss: 0.0739 - acc: 0.8800 - auc: 0.9617 - f1: 0.8800 - val_loss: 0.0822 - val_acc: 0.8579 - val_auc: 0.9531 - val_f1: 0.8579\n",
      "Epoch 20/20\n",
      "66490/66490 [==============================] - 3s 46us/step - loss: 0.0717 - acc: 0.8844 - auc: 0.9640 - f1: 0.8844 - val_loss: 0.0697 - val_acc: 0.8943 - val_auc: 0.9668 - val_f1: 0.8943\n",
      "[[ 2831   251]\n",
      " [ 1506 12035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76      3082\n",
      "           1       0.98      0.89      0.93     13541\n",
      "\n",
      "    accuracy                           0.89     16623\n",
      "   macro avg       0.82      0.90      0.85     16623\n",
      "weighted avg       0.92      0.89      0.90     16623\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (2, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 66491 samples, validate on 16622 samples\n",
      "Epoch 1/20\n",
      "66491/66491 [==============================] - 4s 60us/step - loss: 0.1677 - acc: 0.6985 - auc: 0.7887 - f1: 0.6985 - val_loss: 0.1586 - val_acc: 0.6931 - val_auc: 0.8155 - val_f1: 0.6931\n",
      "Epoch 2/20\n",
      "66491/66491 [==============================] - 3s 42us/step - loss: 0.1561 - acc: 0.7216 - auc: 0.8228 - f1: 0.7216 - val_loss: 0.1534 - val_acc: 0.7956 - val_auc: 0.8393 - val_f1: 0.7956\n",
      "Epoch 3/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.1473 - acc: 0.7484 - auc: 0.8469 - f1: 0.7484 - val_loss: 0.1344 - val_acc: 0.8007 - val_auc: 0.8736 - val_f1: 0.8007\n",
      "Epoch 4/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.1269 - acc: 0.7932 - auc: 0.8900 - f1: 0.7932 - val_loss: 0.1176 - val_acc: 0.8119 - val_auc: 0.9056 - val_f1: 0.8119\n",
      "Epoch 5/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.1130 - acc: 0.8182 - auc: 0.9130 - f1: 0.8182 - val_loss: 0.0997 - val_acc: 0.8395 - val_auc: 0.9318 - val_f1: 0.8395\n",
      "Epoch 6/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.1096 - acc: 0.8263 - auc: 0.9185 - f1: 0.8263 - val_loss: 0.0974 - val_acc: 0.8444 - val_auc: 0.9373 - val_f1: 0.8444\n",
      "Epoch 7/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.0928 - acc: 0.8520 - auc: 0.9414 - f1: 0.8520 - val_loss: 0.0817 - val_acc: 0.8763 - val_auc: 0.9543 - val_f1: 0.8763\n",
      "Epoch 8/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.0916 - acc: 0.8523 - auc: 0.9429 - f1: 0.8523 - val_loss: 0.0799 - val_acc: 0.8796 - val_auc: 0.9555 - val_f1: 0.8796\n",
      "Epoch 9/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0866 - acc: 0.8613 - auc: 0.9485 - f1: 0.8613 - val_loss: 0.0800 - val_acc: 0.8590 - val_auc: 0.9557 - val_f1: 0.8590\n",
      "Epoch 10/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0830 - acc: 0.8659 - auc: 0.9531 - f1: 0.8659 - val_loss: 0.0756 - val_acc: 0.8906 - val_auc: 0.9607 - val_f1: 0.8906\n",
      "Epoch 11/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0796 - acc: 0.8716 - auc: 0.9561 - f1: 0.8716 - val_loss: 0.0957 - val_acc: 0.8469 - val_auc: 0.9389 - val_f1: 0.8469\n",
      "Epoch 12/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0802 - acc: 0.8726 - auc: 0.9564 - f1: 0.8726 - val_loss: 0.0747 - val_acc: 0.8883 - val_auc: 0.9619 - val_f1: 0.8883\n",
      "Epoch 13/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0878 - acc: 0.8638 - auc: 0.9486 - f1: 0.8638 - val_loss: 0.0769 - val_acc: 0.8913 - val_auc: 0.9599 - val_f1: 0.8913\n",
      "Epoch 14/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0755 - acc: 0.8792 - auc: 0.9606 - f1: 0.8792 - val_loss: 0.0680 - val_acc: 0.8998 - val_auc: 0.9680 - val_f1: 0.8998\n",
      "Epoch 15/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0744 - acc: 0.8796 - auc: 0.9617 - f1: 0.8796 - val_loss: 0.0796 - val_acc: 0.8633 - val_auc: 0.9571 - val_f1: 0.8633\n",
      "Epoch 16/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.0755 - acc: 0.8809 - auc: 0.9608 - f1: 0.8809 - val_loss: 0.0708 - val_acc: 0.8929 - val_auc: 0.9657 - val_f1: 0.8929\n",
      "Epoch 17/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0829 - acc: 0.8705 - auc: 0.9534 - f1: 0.8705 - val_loss: 0.0809 - val_acc: 0.8845 - val_auc: 0.9565 - val_f1: 0.8845\n",
      "Epoch 18/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0735 - acc: 0.8853 - auc: 0.9626 - f1: 0.8853 - val_loss: 0.0814 - val_acc: 0.8469 - val_auc: 0.9574 - val_f1: 0.8469\n",
      "Epoch 19/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0732 - acc: 0.8856 - auc: 0.9635 - f1: 0.8856 - val_loss: 0.0665 - val_acc: 0.8957 - val_auc: 0.9690 - val_f1: 0.8957\n",
      "Epoch 20/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0695 - acc: 0.8886 - auc: 0.9661 - f1: 0.8886 - val_loss: 0.0696 - val_acc: 0.8947 - val_auc: 0.9666 - val_f1: 0.8947\n",
      "[[ 2828   254]\n",
      " [ 1496 12044]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76      3082\n",
      "           1       0.98      0.89      0.93     13540\n",
      "\n",
      "    accuracy                           0.89     16622\n",
      "   macro avg       0.82      0.90      0.85     16622\n",
      "weighted avg       0.92      0.89      0.90     16622\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (2, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_13 (GRU)                 (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66491 samples, validate on 16622 samples\n",
      "Epoch 1/20\n",
      "66491/66491 [==============================] - 4s 65us/step - loss: 0.1690 - acc: 0.6958 - auc: 0.7852 - f1: 0.6958 - val_loss: 0.1546 - val_acc: 0.7271 - val_auc: 0.8242 - val_f1: 0.7271\n",
      "Epoch 2/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.1569 - acc: 0.7224 - auc: 0.8218 - f1: 0.7224 - val_loss: 0.1461 - val_acc: 0.7195 - val_auc: 0.8471 - val_f1: 0.7195\n",
      "Epoch 3/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.1456 - acc: 0.7535 - auc: 0.8488 - f1: 0.7535 - val_loss: 0.1329 - val_acc: 0.7831 - val_auc: 0.8758 - val_f1: 0.7831\n",
      "Epoch 4/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.1287 - acc: 0.7879 - auc: 0.8858 - f1: 0.7879 - val_loss: 0.1179 - val_acc: 0.8249 - val_auc: 0.9053 - val_f1: 0.8249\n",
      "Epoch 5/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.1104 - acc: 0.8191 - auc: 0.9171 - f1: 0.8191 - val_loss: 0.1132 - val_acc: 0.8734 - val_auc: 0.9222 - val_f1: 0.8734\n",
      "Epoch 6/20\n",
      "66491/66491 [==============================] - 3s 43us/step - loss: 0.1042 - acc: 0.8280 - auc: 0.9262 - f1: 0.8280 - val_loss: 0.0943 - val_acc: 0.8679 - val_auc: 0.9408 - val_f1: 0.8679\n",
      "Epoch 7/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.1013 - acc: 0.8336 - auc: 0.9306 - f1: 0.8336 - val_loss: 0.1016 - val_acc: 0.8177 - val_auc: 0.9371 - val_f1: 0.8177\n",
      "Epoch 8/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0920 - acc: 0.8509 - auc: 0.9423 - f1: 0.8509 - val_loss: 0.0832 - val_acc: 0.8669 - val_auc: 0.9525 - val_f1: 0.8669\n",
      "Epoch 9/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0869 - acc: 0.8583 - auc: 0.9483 - f1: 0.8583 - val_loss: 0.0801 - val_acc: 0.8850 - val_auc: 0.9565 - val_f1: 0.8850\n",
      "Epoch 10/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0859 - acc: 0.8610 - auc: 0.9492 - f1: 0.8610 - val_loss: 0.0803 - val_acc: 0.8683 - val_auc: 0.9564 - val_f1: 0.8683\n",
      "Epoch 11/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0825 - acc: 0.8659 - auc: 0.9535 - f1: 0.8659 - val_loss: 0.0811 - val_acc: 0.8837 - val_auc: 0.9572 - val_f1: 0.8837\n",
      "Epoch 12/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0843 - acc: 0.8630 - auc: 0.9511 - f1: 0.8630 - val_loss: 0.0711 - val_acc: 0.9006 - val_auc: 0.9659 - val_f1: 0.9006\n",
      "Epoch 13/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0788 - acc: 0.8735 - auc: 0.9568 - f1: 0.8735 - val_loss: 0.1023 - val_acc: 0.8917 - val_auc: 0.9448 - val_f1: 0.8917\n",
      "Epoch 14/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0794 - acc: 0.8729 - auc: 0.9573 - f1: 0.8729 - val_loss: 0.0679 - val_acc: 0.8963 - val_auc: 0.9678 - val_f1: 0.8963\n",
      "Epoch 15/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0775 - acc: 0.8763 - auc: 0.9585 - f1: 0.8763 - val_loss: 0.0695 - val_acc: 0.8915 - val_auc: 0.9668 - val_f1: 0.8915\n",
      "Epoch 16/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0811 - acc: 0.8698 - auc: 0.9547 - f1: 0.8698 - val_loss: 0.0737 - val_acc: 0.8929 - val_auc: 0.9636 - val_f1: 0.8929\n",
      "Epoch 17/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0792 - acc: 0.8720 - auc: 0.9563 - f1: 0.8720 - val_loss: 0.0715 - val_acc: 0.9002 - val_auc: 0.9659 - val_f1: 0.9002\n",
      "Epoch 18/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0843 - acc: 0.8673 - auc: 0.9509 - f1: 0.8673 - val_loss: 0.0723 - val_acc: 0.8948 - val_auc: 0.9642 - val_f1: 0.8948\n",
      "Epoch 19/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0717 - acc: 0.8840 - auc: 0.9644 - f1: 0.8840 - val_loss: 0.0735 - val_acc: 0.9015 - val_auc: 0.9645 - val_f1: 0.9015\n",
      "Epoch 20/20\n",
      "66491/66491 [==============================] - 3s 44us/step - loss: 0.0738 - acc: 0.8806 - auc: 0.9623 - f1: 0.8806 - val_loss: 0.0692 - val_acc: 0.9013 - val_auc: 0.9677 - val_f1: 0.9013\n",
      "[[ 2813   269]\n",
      " [ 1371 12169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77      3082\n",
      "           1       0.98      0.90      0.94     13540\n",
      "\n",
      "    accuracy                           0.90     16622\n",
      "   macro avg       0.83      0.91      0.86     16622\n",
      "weighted avg       0.92      0.90      0.91     16622\n",
      "\n",
      "time (in seconds) 309.37557673454285\n",
      "... DONE!\n",
      "... DONE!\n",
      "window_size: 3\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (110841, 8, 3)\n",
      "tensor input y: (110841, 2)\n",
      "proportion of y labels: (array([0, 1]), array([20714, 90127]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (77588, 3, 8)\n",
      "Tensor y train: (77588, 2)\n",
      "Tensor X test: (33253, 3, 8)\n",
      "Tensor y test: (33253, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (3, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_16 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62070 samples, validate on 15518 samples\n",
      "Epoch 1/20\n",
      "62070/62070 [==============================] - 5s 83us/step - loss: 0.1710 - acc: 0.6925 - auc: 0.7821 - f1: 0.6925 - val_loss: 0.1586 - val_acc: 0.7319 - val_auc: 0.8187 - val_f1: 0.7319\n",
      "Epoch 2/20\n",
      "62070/62070 [==============================] - 4s 59us/step - loss: 0.1597 - acc: 0.7107 - auc: 0.8138 - f1: 0.7107 - val_loss: 0.1536 - val_acc: 0.7321 - val_auc: 0.8283 - val_f1: 0.7321\n",
      "Epoch 3/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.1519 - acc: 0.7275 - auc: 0.8355 - f1: 0.7275 - val_loss: 0.1411 - val_acc: 0.7649 - val_auc: 0.8587 - val_f1: 0.7649\n",
      "Epoch 4/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.1371 - acc: 0.7606 - auc: 0.8685 - f1: 0.7606 - val_loss: 0.1203 - val_acc: 0.8063 - val_auc: 0.9010 - val_f1: 0.8063\n",
      "Epoch 5/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.1174 - acc: 0.8028 - auc: 0.9048 - f1: 0.8028 - val_loss: 0.1104 - val_acc: 0.8340 - val_auc: 0.9187 - val_f1: 0.8340\n",
      "Epoch 6/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.1034 - acc: 0.8258 - auc: 0.9267 - f1: 0.8258 - val_loss: 0.0896 - val_acc: 0.8535 - val_auc: 0.9439 - val_f1: 0.8535\n",
      "Epoch 7/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.0975 - acc: 0.8365 - auc: 0.9344 - f1: 0.8365 - val_loss: 0.0800 - val_acc: 0.8665 - val_auc: 0.9544 - val_f1: 0.8665\n",
      "Epoch 8/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.0887 - acc: 0.8505 - auc: 0.9451 - f1: 0.8505 - val_loss: 0.0977 - val_acc: 0.8287 - val_auc: 0.9361 - val_f1: 0.8287\n",
      "Epoch 9/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0829 - acc: 0.8619 - auc: 0.9512 - f1: 0.8619 - val_loss: 0.1040 - val_acc: 0.8177 - val_auc: 0.9336 - val_f1: 0.8177\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.0848 - acc: 0.8602 - auc: 0.9498 - f1: 0.8602 - val_loss: 0.0700 - val_acc: 0.8892 - val_auc: 0.9656 - val_f1: 0.8892\n",
      "Epoch 11/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.0745 - acc: 0.8770 - auc: 0.9612 - f1: 0.8770 - val_loss: 0.0642 - val_acc: 0.8945 - val_auc: 0.9708 - val_f1: 0.8945\n",
      "Epoch 12/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0711 - acc: 0.8811 - auc: 0.9644 - f1: 0.8811 - val_loss: 0.0620 - val_acc: 0.9075 - val_auc: 0.9727 - val_f1: 0.9075\n",
      "Epoch 13/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0693 - acc: 0.8858 - auc: 0.9659 - f1: 0.8858 - val_loss: 0.0599 - val_acc: 0.9104 - val_auc: 0.9739 - val_f1: 0.9104\n",
      "Epoch 14/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.0739 - acc: 0.8810 - auc: 0.9621 - f1: 0.8810 - val_loss: 0.0627 - val_acc: 0.9087 - val_auc: 0.9723 - val_f1: 0.9087\n",
      "Epoch 15/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.0669 - acc: 0.8912 - auc: 0.9678 - f1: 0.8912 - val_loss: 0.0627 - val_acc: 0.9011 - val_auc: 0.9724 - val_f1: 0.9011\n",
      "Epoch 16/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0651 - acc: 0.8930 - auc: 0.9694 - f1: 0.8930 - val_loss: 0.0716 - val_acc: 0.9095 - val_auc: 0.9681 - val_f1: 0.9095\n",
      "Epoch 17/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0643 - acc: 0.8955 - auc: 0.9704 - f1: 0.8955 - val_loss: 0.0630 - val_acc: 0.8984 - val_auc: 0.9722 - val_f1: 0.8984\n",
      "Epoch 18/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0620 - acc: 0.9014 - auc: 0.9719 - f1: 0.9014 - val_loss: 0.0592 - val_acc: 0.9134 - val_auc: 0.9751 - val_f1: 0.9134\n",
      "Epoch 19/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0614 - acc: 0.9015 - auc: 0.9724 - f1: 0.9015 - val_loss: 0.0652 - val_acc: 0.9181 - val_auc: 0.9725 - val_f1: 0.9181\n",
      "Epoch 20/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0606 - acc: 0.9026 - auc: 0.9731 - f1: 0.9026 - val_loss: 0.0539 - val_acc: 0.9208 - val_auc: 0.9785 - val_f1: 0.9208\n",
      "[[ 2762   143]\n",
      " [ 1086 11527]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82      2905\n",
      "           1       0.99      0.91      0.95     12613\n",
      "\n",
      "    accuracy                           0.92     15518\n",
      "   macro avg       0.85      0.93      0.88     15518\n",
      "weighted avg       0.94      0.92      0.92     15518\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (3, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_19 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_20 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_21 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62070 samples, validate on 15518 samples\n",
      "Epoch 1/20\n",
      "62070/62070 [==============================] - 6s 90us/step - loss: 0.1679 - acc: 0.7011 - auc: 0.7926 - f1: 0.7011 - val_loss: 0.1634 - val_acc: 0.7013 - val_auc: 0.8067 - val_f1: 0.7013\n",
      "Epoch 2/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.1590 - acc: 0.7106 - auc: 0.8165 - f1: 0.7106 - val_loss: 0.1582 - val_acc: 0.7281 - val_auc: 0.8175 - val_f1: 0.7281\n",
      "Epoch 3/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.1517 - acc: 0.7291 - auc: 0.8351 - f1: 0.7291 - val_loss: 0.1442 - val_acc: 0.7514 - val_auc: 0.8526 - val_f1: 0.7514\n",
      "Epoch 4/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.1406 - acc: 0.7526 - auc: 0.8617 - f1: 0.7526 - val_loss: 0.1290 - val_acc: 0.7918 - val_auc: 0.8861 - val_f1: 0.7918\n",
      "Epoch 5/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.1225 - acc: 0.7862 - auc: 0.8966 - f1: 0.7862 - val_loss: 0.1146 - val_acc: 0.8317 - val_auc: 0.9109 - val_f1: 0.8317\n",
      "Epoch 6/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.1093 - acc: 0.8166 - auc: 0.9175 - f1: 0.8166 - val_loss: 0.1037 - val_acc: 0.8293 - val_auc: 0.9265 - val_f1: 0.8293\n",
      "Epoch 7/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0995 - acc: 0.8323 - auc: 0.9319 - f1: 0.8323 - val_loss: 0.0887 - val_acc: 0.8641 - val_auc: 0.9454 - val_f1: 0.8641\n",
      "Epoch 8/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0910 - acc: 0.8481 - auc: 0.9430 - f1: 0.8481 - val_loss: 0.1141 - val_acc: 0.7920 - val_auc: 0.9141 - val_f1: 0.7920\n",
      "Epoch 9/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.0861 - acc: 0.8560 - auc: 0.9487 - f1: 0.8560 - val_loss: 0.0803 - val_acc: 0.8776 - val_auc: 0.9560 - val_f1: 0.8776\n",
      "Epoch 10/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0812 - acc: 0.8667 - auc: 0.9542 - f1: 0.8667 - val_loss: 0.0770 - val_acc: 0.8816 - val_auc: 0.9593 - val_f1: 0.8816\n",
      "Epoch 11/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0772 - acc: 0.8752 - auc: 0.9590 - f1: 0.8752 - val_loss: 0.0670 - val_acc: 0.8977 - val_auc: 0.9678 - val_f1: 0.8977\n",
      "Epoch 12/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0760 - acc: 0.8765 - auc: 0.9599 - f1: 0.8765 - val_loss: 0.0777 - val_acc: 0.8723 - val_auc: 0.9576 - val_f1: 0.8723\n",
      "Epoch 13/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0740 - acc: 0.8803 - auc: 0.9616 - f1: 0.8803 - val_loss: 0.0715 - val_acc: 0.8974 - val_auc: 0.9649 - val_f1: 0.8974\n",
      "Epoch 14/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0731 - acc: 0.8841 - auc: 0.9633 - f1: 0.8841 - val_loss: 0.0670 - val_acc: 0.8917 - val_auc: 0.9684 - val_f1: 0.8917\n",
      "Epoch 15/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0677 - acc: 0.8933 - auc: 0.9678 - f1: 0.8933 - val_loss: 0.0684 - val_acc: 0.9010 - val_auc: 0.9679 - val_f1: 0.9010\n",
      "Epoch 16/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0661 - acc: 0.8954 - auc: 0.9690 - f1: 0.8954 - val_loss: 0.0617 - val_acc: 0.9093 - val_auc: 0.9718 - val_f1: 0.9093\n",
      "Epoch 17/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0640 - acc: 0.8987 - auc: 0.9706 - f1: 0.8987 - val_loss: 0.0577 - val_acc: 0.9138 - val_auc: 0.9752 - val_f1: 0.9138\n",
      "Epoch 18/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0665 - acc: 0.8947 - auc: 0.9685 - f1: 0.8947 - val_loss: 0.0735 - val_acc: 0.8989 - val_auc: 0.9639 - val_f1: 0.8989\n",
      "Epoch 19/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0640 - acc: 0.8991 - auc: 0.9707 - f1: 0.8991 - val_loss: 0.0613 - val_acc: 0.9117 - val_auc: 0.9735 - val_f1: 0.9117\n",
      "Epoch 20/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0618 - acc: 0.9034 - auc: 0.9724 - f1: 0.9034 - val_loss: 0.0612 - val_acc: 0.9048 - val_auc: 0.9734 - val_f1: 0.9048\n",
      "[[ 2764   141]\n",
      " [ 1336 11277]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.95      0.79      2905\n",
      "           1       0.99      0.89      0.94     12613\n",
      "\n",
      "    accuracy                           0.90     15518\n",
      "   macro avg       0.83      0.92      0.86     15518\n",
      "weighted avg       0.93      0.90      0.91     15518\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (3, 8) 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_22 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_24 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62070 samples, validate on 15518 samples\n",
      "Epoch 1/20\n",
      "62070/62070 [==============================] - 6s 94us/step - loss: 0.1712 - acc: 0.6961 - auc: 0.7828 - f1: 0.6961 - val_loss: 0.1583 - val_acc: 0.7234 - val_auc: 0.8169 - val_f1: 0.7234\n",
      "Epoch 2/20\n",
      "62070/62070 [==============================] - 4s 61us/step - loss: 0.1615 - acc: 0.7046 - auc: 0.8092 - f1: 0.7046 - val_loss: 0.1527 - val_acc: 0.7312 - val_auc: 0.8316 - val_f1: 0.7312\n",
      "Epoch 3/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.1537 - acc: 0.7243 - auc: 0.8312 - f1: 0.7243 - val_loss: 0.1396 - val_acc: 0.7468 - val_auc: 0.8610 - val_f1: 0.7468\n",
      "Epoch 4/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.1393 - acc: 0.7600 - auc: 0.8655 - f1: 0.7600 - val_loss: 0.1243 - val_acc: 0.7696 - val_auc: 0.8949 - val_f1: 0.7696\n",
      "Epoch 5/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.1225 - acc: 0.7934 - auc: 0.8979 - f1: 0.7934 - val_loss: 0.1118 - val_acc: 0.8401 - val_auc: 0.9159 - val_f1: 0.8401\n",
      "Epoch 6/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.1085 - acc: 0.8221 - auc: 0.9202 - f1: 0.8221 - val_loss: 0.0947 - val_acc: 0.8348 - val_auc: 0.9399 - val_f1: 0.8348\n",
      "Epoch 7/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0989 - acc: 0.8379 - auc: 0.9332 - f1: 0.8379 - val_loss: 0.0861 - val_acc: 0.8596 - val_auc: 0.9482 - val_f1: 0.8596\n",
      "Epoch 8/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0967 - acc: 0.8425 - auc: 0.9362 - f1: 0.8425 - val_loss: 0.0917 - val_acc: 0.8819 - val_auc: 0.9469 - val_f1: 0.8819\n",
      "Epoch 9/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0896 - acc: 0.8565 - auc: 0.9451 - f1: 0.8565 - val_loss: 0.0911 - val_acc: 0.8261 - val_auc: 0.9453 - val_f1: 0.8261\n",
      "Epoch 10/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0856 - acc: 0.8607 - auc: 0.9496 - f1: 0.8607 - val_loss: 0.0744 - val_acc: 0.8885 - val_auc: 0.9610 - val_f1: 0.8885\n",
      "Epoch 11/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0796 - acc: 0.8721 - auc: 0.9558 - f1: 0.8721 - val_loss: 0.0746 - val_acc: 0.8881 - val_auc: 0.9617 - val_f1: 0.8881\n",
      "Epoch 12/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0779 - acc: 0.8750 - auc: 0.9585 - f1: 0.8750 - val_loss: 0.0747 - val_acc: 0.8836 - val_auc: 0.9614 - val_f1: 0.8836\n",
      "Epoch 13/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0755 - acc: 0.8783 - auc: 0.9602 - f1: 0.8783 - val_loss: 0.0662 - val_acc: 0.8958 - val_auc: 0.9692 - val_f1: 0.8958\n",
      "Epoch 14/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0739 - acc: 0.8822 - auc: 0.9620 - f1: 0.8822 - val_loss: 0.0652 - val_acc: 0.8905 - val_auc: 0.9695 - val_f1: 0.8905\n",
      "Epoch 15/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0712 - acc: 0.8875 - auc: 0.9643 - f1: 0.8875 - val_loss: 0.0666 - val_acc: 0.9015 - val_auc: 0.9698 - val_f1: 0.9015\n",
      "Epoch 16/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0714 - acc: 0.8877 - auc: 0.9642 - f1: 0.8877 - val_loss: 0.0664 - val_acc: 0.8993 - val_auc: 0.9690 - val_f1: 0.8993\n",
      "Epoch 17/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0682 - acc: 0.8923 - auc: 0.9671 - f1: 0.8923 - val_loss: 0.0615 - val_acc: 0.9031 - val_auc: 0.9725 - val_f1: 0.9031\n",
      "Epoch 18/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0653 - acc: 0.8989 - auc: 0.9697 - f1: 0.8989 - val_loss: 0.0599 - val_acc: 0.9135 - val_auc: 0.9739 - val_f1: 0.9135\n",
      "Epoch 19/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0639 - acc: 0.9003 - auc: 0.9708 - f1: 0.9003 - val_loss: 0.0570 - val_acc: 0.9156 - val_auc: 0.9756 - val_f1: 0.9156\n",
      "Epoch 20/20\n",
      "62070/62070 [==============================] - 4s 62us/step - loss: 0.0642 - acc: 0.9001 - auc: 0.9708 - f1: 0.9001 - val_loss: 0.0584 - val_acc: 0.9188 - val_auc: 0.9751 - val_f1: 0.9188\n",
      "[[ 2720   185]\n",
      " [ 1075 11538]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.81      2905\n",
      "           1       0.98      0.91      0.95     12613\n",
      "\n",
      "    accuracy                           0.92     15518\n",
      "   macro avg       0.85      0.93      0.88     15518\n",
      "weighted avg       0.93      0.92      0.92     15518\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (3, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_25 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_26 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_27 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62071 samples, validate on 15517 samples\n",
      "Epoch 1/20\n",
      "62071/62071 [==============================] - 6s 98us/step - loss: 0.1688 - acc: 0.6962 - auc: 0.7890 - f1: 0.6962 - val_loss: 0.1563 - val_acc: 0.7360 - val_auc: 0.8221 - val_f1: 0.7360\n",
      "Epoch 2/20\n",
      "62071/62071 [==============================] - 4s 61us/step - loss: 0.1596 - acc: 0.7112 - auc: 0.8151 - f1: 0.7112 - val_loss: 0.1551 - val_acc: 0.7788 - val_auc: 0.8341 - val_f1: 0.7788\n",
      "Epoch 3/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.1515 - acc: 0.7356 - auc: 0.8356 - f1: 0.7356 - val_loss: 0.1410 - val_acc: 0.7967 - val_auc: 0.8665 - val_f1: 0.7967\n",
      "Epoch 4/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.1387 - acc: 0.7651 - auc: 0.8666 - f1: 0.7651 - val_loss: 0.1253 - val_acc: 0.8167 - val_auc: 0.8952 - val_f1: 0.8167\n",
      "Epoch 5/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.1250 - acc: 0.7932 - auc: 0.8931 - f1: 0.7932 - val_loss: 0.1086 - val_acc: 0.8368 - val_auc: 0.9218 - val_f1: 0.8368\n",
      "Epoch 6/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.1112 - acc: 0.8203 - auc: 0.9163 - f1: 0.8203 - val_loss: 0.1010 - val_acc: 0.8591 - val_auc: 0.9363 - val_f1: 0.8591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.1031 - acc: 0.8343 - auc: 0.9293 - f1: 0.8343 - val_loss: 0.1019 - val_acc: 0.8505 - val_auc: 0.9324 - val_f1: 0.8505\n",
      "Epoch 8/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0958 - acc: 0.8495 - auc: 0.9385 - f1: 0.8495 - val_loss: 0.0856 - val_acc: 0.8889 - val_auc: 0.9542 - val_f1: 0.8889\n",
      "Epoch 9/20\n",
      "62071/62071 [==============================] - 4s 61us/step - loss: 0.0881 - acc: 0.8602 - auc: 0.9477 - f1: 0.8602 - val_loss: 0.0792 - val_acc: 0.8726 - val_auc: 0.9581 - val_f1: 0.8726\n",
      "Epoch 10/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0838 - acc: 0.8667 - auc: 0.9529 - f1: 0.8667 - val_loss: 0.0769 - val_acc: 0.8821 - val_auc: 0.9599 - val_f1: 0.8821\n",
      "Epoch 11/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0814 - acc: 0.8714 - auc: 0.9550 - f1: 0.8714 - val_loss: 0.0707 - val_acc: 0.8943 - val_auc: 0.9654 - val_f1: 0.8943\n",
      "Epoch 12/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0762 - acc: 0.8806 - auc: 0.9603 - f1: 0.8806 - val_loss: 0.0768 - val_acc: 0.8933 - val_auc: 0.9611 - val_f1: 0.8933\n",
      "Epoch 13/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0764 - acc: 0.8792 - auc: 0.9603 - f1: 0.8792 - val_loss: 0.0664 - val_acc: 0.9149 - val_auc: 0.9705 - val_f1: 0.9149\n",
      "Epoch 14/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0744 - acc: 0.8850 - auc: 0.9622 - f1: 0.8850 - val_loss: 0.0678 - val_acc: 0.9024 - val_auc: 0.9684 - val_f1: 0.9024\n",
      "Epoch 15/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0715 - acc: 0.8877 - auc: 0.9647 - f1: 0.8877 - val_loss: 0.0732 - val_acc: 0.9072 - val_auc: 0.9649 - val_f1: 0.9072\n",
      "Epoch 16/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0692 - acc: 0.8932 - auc: 0.9669 - f1: 0.8932 - val_loss: 0.0644 - val_acc: 0.9102 - val_auc: 0.9715 - val_f1: 0.9102\n",
      "Epoch 17/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0690 - acc: 0.8933 - auc: 0.9675 - f1: 0.8933 - val_loss: 0.0682 - val_acc: 0.9060 - val_auc: 0.9687 - val_f1: 0.9060\n",
      "Epoch 18/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0653 - acc: 0.8984 - auc: 0.9701 - f1: 0.8984 - val_loss: 0.0631 - val_acc: 0.9071 - val_auc: 0.9730 - val_f1: 0.9071\n",
      "Epoch 19/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0654 - acc: 0.8995 - auc: 0.9701 - f1: 0.8995 - val_loss: 0.0641 - val_acc: 0.9057 - val_auc: 0.9717 - val_f1: 0.9057\n",
      "Epoch 20/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0651 - acc: 0.8984 - auc: 0.9703 - f1: 0.8984 - val_loss: 0.0615 - val_acc: 0.9183 - val_auc: 0.9751 - val_f1: 0.9183\n",
      "[[ 2674   230]\n",
      " [ 1038 11575]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81      2904\n",
      "           1       0.98      0.92      0.95     12613\n",
      "\n",
      "    accuracy                           0.92     15517\n",
      "   macro avg       0.85      0.92      0.88     15517\n",
      "weighted avg       0.93      0.92      0.92     15517\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (3, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_28 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_29 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_30 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 62071 samples, validate on 15517 samples\n",
      "Epoch 1/20\n",
      "62071/62071 [==============================] - 6s 101us/step - loss: 0.1703 - acc: 0.6985 - auc: 0.7844 - f1: 0.6985 - val_loss: 0.1683 - val_acc: 0.6209 - val_auc: 0.8095 - val_f1: 0.6209\n",
      "Epoch 2/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.1593 - acc: 0.7128 - auc: 0.8148 - f1: 0.7128 - val_loss: 0.1576 - val_acc: 0.7211 - val_auc: 0.8201 - val_f1: 0.7211\n",
      "Epoch 3/20\n",
      "62071/62071 [==============================] - 4s 64us/step - loss: 0.1537 - acc: 0.7248 - auc: 0.8296 - f1: 0.7248 - val_loss: 0.1460 - val_acc: 0.7727 - val_auc: 0.8518 - val_f1: 0.7727\n",
      "Epoch 4/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.1408 - acc: 0.7552 - auc: 0.8597 - f1: 0.7552 - val_loss: 0.1322 - val_acc: 0.7866 - val_auc: 0.8806 - val_f1: 0.7866\n",
      "Epoch 5/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.1296 - acc: 0.7820 - auc: 0.8847 - f1: 0.7820 - val_loss: 0.1213 - val_acc: 0.7843 - val_auc: 0.9014 - val_f1: 0.7843\n",
      "Epoch 6/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.1152 - acc: 0.8124 - auc: 0.9103 - f1: 0.8124 - val_loss: 0.1063 - val_acc: 0.8274 - val_auc: 0.9239 - val_f1: 0.8274\n",
      "Epoch 7/20\n",
      "62071/62071 [==============================] - 4s 64us/step - loss: 0.1028 - acc: 0.8354 - auc: 0.9288 - f1: 0.8354 - val_loss: 0.0998 - val_acc: 0.8360 - val_auc: 0.9333 - val_f1: 0.8360\n",
      "Epoch 8/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.0944 - acc: 0.8500 - auc: 0.9405 - f1: 0.8500 - val_loss: 0.0899 - val_acc: 0.8556 - val_auc: 0.9454 - val_f1: 0.8556\n",
      "Epoch 9/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.0901 - acc: 0.8559 - auc: 0.9454 - f1: 0.8559 - val_loss: 0.0788 - val_acc: 0.8697 - val_auc: 0.9574 - val_f1: 0.8697\n",
      "Epoch 10/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.0816 - acc: 0.8699 - auc: 0.9550 - f1: 0.8699 - val_loss: 0.0765 - val_acc: 0.8883 - val_auc: 0.9596 - val_f1: 0.8883\n",
      "Epoch 11/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.0798 - acc: 0.8738 - auc: 0.9569 - f1: 0.8738 - val_loss: 0.0845 - val_acc: 0.8556 - val_auc: 0.9541 - val_f1: 0.8556\n",
      "Epoch 12/20\n",
      "62071/62071 [==============================] - 4s 64us/step - loss: 0.0784 - acc: 0.8762 - auc: 0.9584 - f1: 0.8762 - val_loss: 0.0767 - val_acc: 0.8729 - val_auc: 0.9603 - val_f1: 0.8729\n",
      "Epoch 13/20\n",
      "62071/62071 [==============================] - 4s 64us/step - loss: 0.0745 - acc: 0.8823 - auc: 0.9619 - f1: 0.8823 - val_loss: 0.0700 - val_acc: 0.8826 - val_auc: 0.9670 - val_f1: 0.8826\n",
      "Epoch 14/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.0717 - acc: 0.8858 - auc: 0.9640 - f1: 0.8858 - val_loss: 0.0857 - val_acc: 0.8926 - val_auc: 0.9550 - val_f1: 0.8926\n",
      "Epoch 15/20\n",
      "62071/62071 [==============================] - 4s 62us/step - loss: 0.0768 - acc: 0.8807 - auc: 0.9596 - f1: 0.8807 - val_loss: 0.0628 - val_acc: 0.9123 - val_auc: 0.9717 - val_f1: 0.9123\n",
      "Epoch 16/20\n",
      "62071/62071 [==============================] - 4s 63us/step - loss: 0.0678 - acc: 0.8935 - auc: 0.9678 - f1: 0.8935 - val_loss: 0.0694 - val_acc: 0.9118 - val_auc: 0.9685 - val_f1: 0.9118\n",
      "Epoch 17/20\n",
      "62071/62071 [==============================] - 4s 61us/step - loss: 0.0660 - acc: 0.8962 - auc: 0.9698 - f1: 0.8962 - val_loss: 0.0688 - val_acc: 0.8873 - val_auc: 0.9677 - val_f1: 0.8873\n",
      "Epoch 18/20\n",
      "62071/62071 [==============================] - 4s 61us/step - loss: 0.0668 - acc: 0.8949 - auc: 0.9688 - f1: 0.8949 - val_loss: 0.0623 - val_acc: 0.9180 - val_auc: 0.9733 - val_f1: 0.9180\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62071/62071 [==============================] - 4s 61us/step - loss: 0.0620 - acc: 0.9023 - auc: 0.9726 - f1: 0.9023 - val_loss: 0.0667 - val_acc: 0.8870 - val_auc: 0.9691 - val_f1: 0.8870\n",
      "Epoch 20/20\n",
      "62071/62071 [==============================] - 4s 61us/step - loss: 0.0624 - acc: 0.9022 - auc: 0.9725 - f1: 0.9022 - val_loss: 0.0608 - val_acc: 0.9017 - val_auc: 0.9740 - val_f1: 0.9017\n",
      "[[ 2761   143]\n",
      " [ 1382 11231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.95      0.78      2904\n",
      "           1       0.99      0.89      0.94     12613\n",
      "\n",
      "    accuracy                           0.90     15517\n",
      "   macro avg       0.83      0.92      0.86     15517\n",
      "weighted avg       0.93      0.90      0.91     15517\n",
      "\n",
      "time (in seconds) 408.2010519504547\n",
      "... DONE!\n",
      "... DONE!\n",
      "window_size: 4\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (103384, 8, 4)\n",
      "tensor input y: (103384, 2)\n",
      "proportion of y labels: (array([0, 1]), array([19717, 83667]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (72368, 4, 8)\n",
      "Tensor y train: (72368, 2)\n",
      "Tensor X test: (31016, 4, 8)\n",
      "Tensor y test: (31016, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_31 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_32 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_33 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 57894 samples, validate on 14474 samples\n",
      "Epoch 1/20\n",
      "57894/57894 [==============================] - 7s 122us/step - loss: 0.1731 - acc: 0.6984 - auc: 0.7879 - f1: 0.6984 - val_loss: 0.1602 - val_acc: 0.7031 - val_auc: 0.8208 - val_f1: 0.7031\n",
      "Epoch 2/20\n",
      "57894/57894 [==============================] - 5s 78us/step - loss: 0.1628 - acc: 0.7159 - auc: 0.8156 - f1: 0.7159 - val_loss: 0.1559 - val_acc: 0.7179 - val_auc: 0.8307 - val_f1: 0.7179\n",
      "Epoch 3/20\n",
      "57894/57894 [==============================] - 5s 83us/step - loss: 0.1565 - acc: 0.7289 - auc: 0.8313 - f1: 0.7289 - val_loss: 0.1480 - val_acc: 0.7826 - val_auc: 0.8537 - val_f1: 0.7826\n",
      "Epoch 4/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.1442 - acc: 0.7567 - auc: 0.8594 - f1: 0.7567 - val_loss: 0.1315 - val_acc: 0.8001 - val_auc: 0.8851 - val_f1: 0.8001\n",
      "Epoch 5/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.1288 - acc: 0.7879 - auc: 0.8911 - f1: 0.7879 - val_loss: 0.1177 - val_acc: 0.8187 - val_auc: 0.9101 - val_f1: 0.8187\n",
      "Epoch 6/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.1126 - acc: 0.8206 - auc: 0.9178 - f1: 0.8206 - val_loss: 0.1088 - val_acc: 0.8042 - val_auc: 0.9248 - val_f1: 0.8042\n",
      "Epoch 7/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.1046 - acc: 0.8352 - auc: 0.9283 - f1: 0.8352 - val_loss: 0.0883 - val_acc: 0.8656 - val_auc: 0.9479 - val_f1: 0.8656\n",
      "Epoch 8/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0938 - acc: 0.8526 - auc: 0.9427 - f1: 0.8526 - val_loss: 0.0832 - val_acc: 0.8807 - val_auc: 0.9552 - val_f1: 0.8807\n",
      "Epoch 9/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0863 - acc: 0.8649 - auc: 0.9505 - f1: 0.8649 - val_loss: 0.0811 - val_acc: 0.8977 - val_auc: 0.9612 - val_f1: 0.8977\n",
      "Epoch 10/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0811 - acc: 0.8721 - auc: 0.9569 - f1: 0.8721 - val_loss: 0.0731 - val_acc: 0.8926 - val_auc: 0.9642 - val_f1: 0.8926\n",
      "Epoch 11/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0764 - acc: 0.8795 - auc: 0.9608 - f1: 0.8795 - val_loss: 0.0743 - val_acc: 0.9076 - val_auc: 0.9667 - val_f1: 0.9076\n",
      "Epoch 12/20\n",
      "57894/57894 [==============================] - 5s 83us/step - loss: 0.0735 - acc: 0.8871 - auc: 0.9639 - f1: 0.8871 - val_loss: 0.0655 - val_acc: 0.9005 - val_auc: 0.9704 - val_f1: 0.9005\n",
      "Epoch 13/20\n",
      "57894/57894 [==============================] - 5s 83us/step - loss: 0.0727 - acc: 0.8855 - auc: 0.9643 - f1: 0.8855 - val_loss: 0.0722 - val_acc: 0.9067 - val_auc: 0.9676 - val_f1: 0.9067\n",
      "Epoch 14/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0689 - acc: 0.8939 - auc: 0.9679 - f1: 0.8939 - val_loss: 0.0645 - val_acc: 0.8972 - val_auc: 0.9724 - val_f1: 0.8972\n",
      "Epoch 15/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0680 - acc: 0.8943 - auc: 0.9686 - f1: 0.8943 - val_loss: 0.0792 - val_acc: 0.8698 - val_auc: 0.9599 - val_f1: 0.8698\n",
      "Epoch 16/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0735 - acc: 0.8868 - auc: 0.9636 - f1: 0.8868 - val_loss: 0.0634 - val_acc: 0.9156 - val_auc: 0.9727 - val_f1: 0.9156\n",
      "Epoch 17/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0656 - acc: 0.9007 - auc: 0.9706 - f1: 0.9007 - val_loss: 0.0617 - val_acc: 0.9051 - val_auc: 0.9735 - val_f1: 0.9051\n",
      "Epoch 18/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0632 - acc: 0.9036 - auc: 0.9723 - f1: 0.9036 - val_loss: 0.0590 - val_acc: 0.9210 - val_auc: 0.9769 - val_f1: 0.9210\n",
      "Epoch 19/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0619 - acc: 0.9042 - auc: 0.9733 - f1: 0.9042 - val_loss: 0.0622 - val_acc: 0.9223 - val_auc: 0.9755 - val_f1: 0.9223\n",
      "Epoch 20/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.0624 - acc: 0.9050 - auc: 0.9731 - f1: 0.9050 - val_loss: 0.0586 - val_acc: 0.9167 - val_auc: 0.9762 - val_f1: 0.9167\n",
      "[[ 2581   193]\n",
      " [ 1012 10688]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81      2774\n",
      "           1       0.98      0.91      0.95     11700\n",
      "\n",
      "    accuracy                           0.92     14474\n",
      "   macro avg       0.85      0.92      0.88     14474\n",
      "weighted avg       0.93      0.92      0.92     14474\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_34 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_35 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_36 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57894 samples, validate on 14474 samples\n",
      "Epoch 1/20\n",
      "57894/57894 [==============================] - 7s 127us/step - loss: 0.1732 - acc: 0.6965 - auc: 0.7869 - f1: 0.6965 - val_loss: 0.1626 - val_acc: 0.6714 - val_auc: 0.8206 - val_f1: 0.6714\n",
      "Epoch 2/20\n",
      "57894/57894 [==============================] - 5s 78us/step - loss: 0.1623 - acc: 0.7088 - auc: 0.8158 - f1: 0.7088 - val_loss: 0.1571 - val_acc: 0.7218 - val_auc: 0.8286 - val_f1: 0.7218\n",
      "Epoch 3/20\n",
      "57894/57894 [==============================] - 5s 79us/step - loss: 0.1567 - acc: 0.7242 - auc: 0.8294 - f1: 0.7242 - val_loss: 0.1516 - val_acc: 0.7626 - val_auc: 0.8429 - val_f1: 0.7626\n",
      "Epoch 4/20\n",
      "57894/57894 [==============================] - 5s 79us/step - loss: 0.1474 - acc: 0.7456 - auc: 0.8517 - f1: 0.7456 - val_loss: 0.1377 - val_acc: 0.7890 - val_auc: 0.8713 - val_f1: 0.7890\n",
      "Epoch 5/20\n",
      "57894/57894 [==============================] - 5s 82us/step - loss: 0.1322 - acc: 0.7809 - auc: 0.8837 - f1: 0.7809 - val_loss: 0.1271 - val_acc: 0.7462 - val_auc: 0.9008 - val_f1: 0.7462\n",
      "Epoch 6/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.1210 - acc: 0.8010 - auc: 0.9050 - f1: 0.8010 - val_loss: 0.1060 - val_acc: 0.8325 - val_auc: 0.9264 - val_f1: 0.8325\n",
      "Epoch 7/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.1071 - acc: 0.8300 - auc: 0.9249 - f1: 0.8300 - val_loss: 0.1021 - val_acc: 0.8450 - val_auc: 0.9337 - val_f1: 0.8450\n",
      "Epoch 8/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0980 - acc: 0.8456 - auc: 0.9368 - f1: 0.8456 - val_loss: 0.0884 - val_acc: 0.8691 - val_auc: 0.9482 - val_f1: 0.8691\n",
      "Epoch 9/20\n",
      "57894/57894 [==============================] - 5s 86us/step - loss: 0.0875 - acc: 0.8634 - auc: 0.9490 - f1: 0.8634 - val_loss: 0.0816 - val_acc: 0.8693 - val_auc: 0.9546 - val_f1: 0.8693\n",
      "Epoch 10/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0823 - acc: 0.8695 - auc: 0.9548 - f1: 0.8695 - val_loss: 0.0814 - val_acc: 0.8543 - val_auc: 0.9555 - val_f1: 0.8543\n",
      "Epoch 11/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0802 - acc: 0.8717 - auc: 0.9569 - f1: 0.8717 - val_loss: 0.0747 - val_acc: 0.8854 - val_auc: 0.9627 - val_f1: 0.8854\n",
      "Epoch 12/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0753 - acc: 0.8802 - auc: 0.9615 - f1: 0.8802 - val_loss: 0.0771 - val_acc: 0.8787 - val_auc: 0.9601 - val_f1: 0.8787\n",
      "Epoch 13/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0722 - acc: 0.8862 - auc: 0.9648 - f1: 0.8862 - val_loss: 0.0694 - val_acc: 0.8944 - val_auc: 0.9679 - val_f1: 0.8944\n",
      "Epoch 14/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0704 - acc: 0.8888 - auc: 0.9665 - f1: 0.8888 - val_loss: 0.0686 - val_acc: 0.8788 - val_auc: 0.9683 - val_f1: 0.8788\n",
      "Epoch 15/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0674 - acc: 0.8938 - auc: 0.9688 - f1: 0.8938 - val_loss: 0.0700 - val_acc: 0.9079 - val_auc: 0.9700 - val_f1: 0.9079\n",
      "Epoch 16/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0644 - acc: 0.8984 - auc: 0.9712 - f1: 0.8984 - val_loss: 0.0664 - val_acc: 0.8989 - val_auc: 0.9712 - val_f1: 0.8989\n",
      "Epoch 17/20\n",
      "57894/57894 [==============================] - 5s 86us/step - loss: 0.0624 - acc: 0.9027 - auc: 0.9732 - f1: 0.9027 - val_loss: 0.0677 - val_acc: 0.9093 - val_auc: 0.9707 - val_f1: 0.9093\n",
      "Epoch 18/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0631 - acc: 0.9030 - auc: 0.9725 - f1: 0.9030 - val_loss: 0.0641 - val_acc: 0.9084 - val_auc: 0.9721 - val_f1: 0.9084\n",
      "Epoch 19/20\n",
      "57894/57894 [==============================] - 5s 86us/step - loss: 0.0615 - acc: 0.9038 - auc: 0.9735 - f1: 0.9038 - val_loss: 0.0671 - val_acc: 0.9032 - val_auc: 0.9709 - val_f1: 0.9032\n",
      "Epoch 20/20\n",
      "57894/57894 [==============================] - 5s 87us/step - loss: 0.0602 - acc: 0.9072 - auc: 0.9745 - f1: 0.9072 - val_loss: 0.0639 - val_acc: 0.9126 - val_auc: 0.9740 - val_f1: 0.9126\n",
      "[[ 2587   187]\n",
      " [ 1078 10622]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.80      2774\n",
      "           1       0.98      0.91      0.94     11700\n",
      "\n",
      "    accuracy                           0.91     14474\n",
      "   macro avg       0.84      0.92      0.87     14474\n",
      "weighted avg       0.93      0.91      0.92     14474\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_37 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_38 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_39 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 57894 samples, validate on 14474 samples\n",
      "Epoch 1/20\n",
      "57894/57894 [==============================] - 8s 131us/step - loss: 0.1742 - acc: 0.6943 - auc: 0.7833 - f1: 0.6943 - val_loss: 0.1617 - val_acc: 0.7255 - val_auc: 0.8182 - val_f1: 0.7255\n",
      "Epoch 2/20\n",
      "57894/57894 [==============================] - 5s 78us/step - loss: 0.1625 - acc: 0.7122 - auc: 0.8145 - f1: 0.7122 - val_loss: 0.1605 - val_acc: 0.7677 - val_auc: 0.8264 - val_f1: 0.7677\n",
      "Epoch 3/20\n",
      "57894/57894 [==============================] - 5s 79us/step - loss: 0.1587 - acc: 0.7214 - auc: 0.8258 - f1: 0.7214 - val_loss: 0.1552 - val_acc: 0.7140 - val_auc: 0.8323 - val_f1: 0.7140\n",
      "Epoch 4/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.1496 - acc: 0.7411 - auc: 0.8483 - f1: 0.7411 - val_loss: 0.1455 - val_acc: 0.8101 - val_auc: 0.8700 - val_f1: 0.8101\n",
      "Epoch 5/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.1348 - acc: 0.7782 - auc: 0.8794 - f1: 0.7782 - val_loss: 0.1235 - val_acc: 0.8369 - val_auc: 0.9024 - val_f1: 0.8369\n",
      "Epoch 6/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.1211 - acc: 0.8094 - auc: 0.9049 - f1: 0.8094 - val_loss: 0.1056 - val_acc: 0.8544 - val_auc: 0.9287 - val_f1: 0.8544\n",
      "Epoch 7/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.1078 - acc: 0.8328 - auc: 0.9249 - f1: 0.8328 - val_loss: 0.0919 - val_acc: 0.8755 - val_auc: 0.9454 - val_f1: 0.8755\n",
      "Epoch 8/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0958 - acc: 0.8535 - auc: 0.9401 - f1: 0.8535 - val_loss: 0.0832 - val_acc: 0.8510 - val_auc: 0.9555 - val_f1: 0.8510\n",
      "Epoch 9/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0895 - acc: 0.8604 - auc: 0.9479 - f1: 0.8604 - val_loss: 0.0751 - val_acc: 0.8889 - val_auc: 0.9624 - val_f1: 0.8889\n",
      "Epoch 10/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0821 - acc: 0.8720 - auc: 0.9555 - f1: 0.8720 - val_loss: 0.0712 - val_acc: 0.8969 - val_auc: 0.9661 - val_f1: 0.8969\n",
      "Epoch 11/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0786 - acc: 0.8756 - auc: 0.9588 - f1: 0.8756 - val_loss: 0.0791 - val_acc: 0.8581 - val_auc: 0.9605 - val_f1: 0.8581\n",
      "Epoch 12/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0738 - acc: 0.8836 - auc: 0.9635 - f1: 0.8836 - val_loss: 0.0669 - val_acc: 0.8901 - val_auc: 0.9691 - val_f1: 0.8901\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0696 - acc: 0.8911 - auc: 0.9672 - f1: 0.8911 - val_loss: 0.0632 - val_acc: 0.9103 - val_auc: 0.9723 - val_f1: 0.9103\n",
      "Epoch 14/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0701 - acc: 0.8909 - auc: 0.9669 - f1: 0.8909 - val_loss: 0.0675 - val_acc: 0.9139 - val_auc: 0.9714 - val_f1: 0.9139\n",
      "Epoch 15/20\n",
      "57894/57894 [==============================] - 5s 79us/step - loss: 0.0703 - acc: 0.8916 - auc: 0.9665 - f1: 0.8916 - val_loss: 0.0590 - val_acc: 0.9170 - val_auc: 0.9751 - val_f1: 0.9170\n",
      "Epoch 16/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0681 - acc: 0.8939 - auc: 0.9685 - f1: 0.8939 - val_loss: 0.0589 - val_acc: 0.9065 - val_auc: 0.9755 - val_f1: 0.9065\n",
      "Epoch 17/20\n",
      "57894/57894 [==============================] - 5s 79us/step - loss: 0.0650 - acc: 0.8985 - auc: 0.9710 - f1: 0.8985 - val_loss: 0.0583 - val_acc: 0.9219 - val_auc: 0.9755 - val_f1: 0.9219\n",
      "Epoch 18/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0621 - acc: 0.9059 - auc: 0.9732 - f1: 0.9059 - val_loss: 0.0555 - val_acc: 0.9222 - val_auc: 0.9777 - val_f1: 0.9222\n",
      "Epoch 19/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0607 - acc: 0.9067 - auc: 0.9741 - f1: 0.9067 - val_loss: 0.0584 - val_acc: 0.9181 - val_auc: 0.9756 - val_f1: 0.9181\n",
      "Epoch 20/20\n",
      "57894/57894 [==============================] - 5s 80us/step - loss: 0.0621 - acc: 0.9067 - auc: 0.9734 - f1: 0.9067 - val_loss: 0.0539 - val_acc: 0.9251 - val_auc: 0.9784 - val_f1: 0.9251\n",
      "[[ 2635   139]\n",
      " [  945 10755]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83      2774\n",
      "           1       0.99      0.92      0.95     11700\n",
      "\n",
      "    accuracy                           0.93     14474\n",
      "   macro avg       0.86      0.93      0.89     14474\n",
      "weighted avg       0.94      0.93      0.93     14474\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_40 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_41 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_42 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 57895 samples, validate on 14473 samples\n",
      "Epoch 1/20\n",
      "57895/57895 [==============================] - 8s 138us/step - loss: 0.1719 - acc: 0.6997 - auc: 0.7890 - f1: 0.6997 - val_loss: 0.1620 - val_acc: 0.7187 - val_auc: 0.8161 - val_f1: 0.7187\n",
      "Epoch 2/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1621 - acc: 0.7138 - auc: 0.8170 - f1: 0.7138 - val_loss: 0.1619 - val_acc: 0.7546 - val_auc: 0.8205 - val_f1: 0.7546\n",
      "Epoch 3/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1576 - acc: 0.7209 - auc: 0.8271 - f1: 0.7209 - val_loss: 0.1544 - val_acc: 0.7616 - val_auc: 0.8366 - val_f1: 0.7616\n",
      "Epoch 4/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1511 - acc: 0.7404 - auc: 0.8445 - f1: 0.7404 - val_loss: 0.1420 - val_acc: 0.7597 - val_auc: 0.8650 - val_f1: 0.7597\n",
      "Epoch 5/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1373 - acc: 0.7680 - auc: 0.8736 - f1: 0.7680 - val_loss: 0.1263 - val_acc: 0.7701 - val_auc: 0.8942 - val_f1: 0.7701\n",
      "Epoch 6/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1220 - acc: 0.8016 - auc: 0.9023 - f1: 0.8016 - val_loss: 0.1080 - val_acc: 0.8485 - val_auc: 0.9248 - val_f1: 0.8485\n",
      "Epoch 7/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1059 - acc: 0.8341 - auc: 0.9271 - f1: 0.8341 - val_loss: 0.0946 - val_acc: 0.8483 - val_auc: 0.9412 - val_f1: 0.8483\n",
      "Epoch 8/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0950 - acc: 0.8505 - auc: 0.9410 - f1: 0.8505 - val_loss: 0.0821 - val_acc: 0.8827 - val_auc: 0.9559 - val_f1: 0.8827\n",
      "Epoch 9/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0865 - acc: 0.8665 - auc: 0.9510 - f1: 0.8665 - val_loss: 0.0810 - val_acc: 0.8577 - val_auc: 0.9587 - val_f1: 0.8577\n",
      "Epoch 10/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0856 - acc: 0.8597 - auc: 0.9512 - f1: 0.8597 - val_loss: 0.0751 - val_acc: 0.8961 - val_auc: 0.9619 - val_f1: 0.8961\n",
      "Epoch 11/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0768 - acc: 0.8818 - auc: 0.9607 - f1: 0.8818 - val_loss: 0.0675 - val_acc: 0.8962 - val_auc: 0.9693 - val_f1: 0.8962\n",
      "Epoch 12/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0739 - acc: 0.8855 - auc: 0.9631 - f1: 0.8855 - val_loss: 0.0671 - val_acc: 0.9010 - val_auc: 0.9701 - val_f1: 0.9010\n",
      "Epoch 13/20\n",
      "57895/57895 [==============================] - 5s 82us/step - loss: 0.0706 - acc: 0.8936 - auc: 0.9665 - f1: 0.8936 - val_loss: 0.1314 - val_acc: 0.7622 - val_auc: 0.9159 - val_f1: 0.7622\n",
      "Epoch 14/20\n",
      "57895/57895 [==============================] - 5s 83us/step - loss: 0.0726 - acc: 0.8887 - auc: 0.9645 - f1: 0.8887 - val_loss: 0.0670 - val_acc: 0.9055 - val_auc: 0.9698 - val_f1: 0.9055\n",
      "Epoch 15/20\n",
      "57895/57895 [==============================] - 5s 84us/step - loss: 0.0668 - acc: 0.8976 - auc: 0.9692 - f1: 0.8976 - val_loss: 0.0578 - val_acc: 0.9138 - val_auc: 0.9765 - val_f1: 0.9138\n",
      "Epoch 16/20\n",
      "57895/57895 [==============================] - 5s 83us/step - loss: 0.0668 - acc: 0.8974 - auc: 0.9698 - f1: 0.8974 - val_loss: 0.0607 - val_acc: 0.9102 - val_auc: 0.9743 - val_f1: 0.9102\n",
      "Epoch 17/20\n",
      "57895/57895 [==============================] - 5s 83us/step - loss: 0.0658 - acc: 0.8987 - auc: 0.9706 - f1: 0.8987 - val_loss: 0.0595 - val_acc: 0.9152 - val_auc: 0.9756 - val_f1: 0.9152\n",
      "Epoch 18/20\n",
      "57895/57895 [==============================] - 5s 83us/step - loss: 0.0629 - acc: 0.9048 - auc: 0.9727 - f1: 0.9048 - val_loss: 0.0595 - val_acc: 0.9260 - val_auc: 0.9770 - val_f1: 0.9260\n",
      "Epoch 19/20\n",
      "57895/57895 [==============================] - 5s 86us/step - loss: 0.0616 - acc: 0.9084 - auc: 0.9740 - f1: 0.9084 - val_loss: 0.0604 - val_acc: 0.9189 - val_auc: 0.9759 - val_f1: 0.9189\n",
      "Epoch 20/20\n",
      "57895/57895 [==============================] - 5s 89us/step - loss: 0.0616 - acc: 0.9083 - auc: 0.9739 - f1: 0.9083 - val_loss: 0.0589 - val_acc: 0.9237 - val_auc: 0.9764 - val_f1: 0.9237\n",
      "[[ 2545   228]\n",
      " [  877 10823]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82      2773\n",
      "           1       0.98      0.93      0.95     11700\n",
      "\n",
      "    accuracy                           0.92     14473\n",
      "   macro avg       0.86      0.92      0.89     14473\n",
      "weighted avg       0.93      0.92      0.93     14473\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_43 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_44 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_45 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57895 samples, validate on 14473 samples\n",
      "Epoch 1/20\n",
      "57895/57895 [==============================] - 8s 140us/step - loss: 0.1722 - acc: 0.6990 - auc: 0.7878 - f1: 0.6990 - val_loss: 0.1613 - val_acc: 0.7308 - val_auc: 0.8186 - val_f1: 0.7308\n",
      "Epoch 2/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1614 - acc: 0.7160 - auc: 0.8185 - f1: 0.7160 - val_loss: 0.1552 - val_acc: 0.7431 - val_auc: 0.8318 - val_f1: 0.7431\n",
      "Epoch 3/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1558 - acc: 0.7306 - auc: 0.8322 - f1: 0.7306 - val_loss: 0.1480 - val_acc: 0.7689 - val_auc: 0.8548 - val_f1: 0.7689\n",
      "Epoch 4/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1451 - acc: 0.7547 - auc: 0.8578 - f1: 0.7547 - val_loss: 0.1377 - val_acc: 0.7399 - val_auc: 0.8760 - val_f1: 0.7399\n",
      "Epoch 5/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1338 - acc: 0.7770 - auc: 0.8815 - f1: 0.7770 - val_loss: 0.1195 - val_acc: 0.8194 - val_auc: 0.9067 - val_f1: 0.8194\n",
      "Epoch 6/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1191 - acc: 0.8069 - auc: 0.9076 - f1: 0.8069 - val_loss: 0.1043 - val_acc: 0.8138 - val_auc: 0.9307 - val_f1: 0.8138\n",
      "Epoch 7/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.1050 - acc: 0.8333 - auc: 0.9277 - f1: 0.8333 - val_loss: 0.0916 - val_acc: 0.8364 - val_auc: 0.9474 - val_f1: 0.8364\n",
      "Epoch 8/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0990 - acc: 0.8412 - auc: 0.9363 - f1: 0.8412 - val_loss: 0.0923 - val_acc: 0.8581 - val_auc: 0.9462 - val_f1: 0.8581\n",
      "Epoch 9/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0913 - acc: 0.8533 - auc: 0.9443 - f1: 0.8533 - val_loss: 0.0829 - val_acc: 0.8716 - val_auc: 0.9548 - val_f1: 0.8716\n",
      "Epoch 10/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0846 - acc: 0.8656 - auc: 0.9523 - f1: 0.8656 - val_loss: 0.0707 - val_acc: 0.8923 - val_auc: 0.9653 - val_f1: 0.8923\n",
      "Epoch 11/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0804 - acc: 0.8756 - auc: 0.9567 - f1: 0.8756 - val_loss: 0.0760 - val_acc: 0.8687 - val_auc: 0.9616 - val_f1: 0.8687\n",
      "Epoch 12/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0774 - acc: 0.8784 - auc: 0.9598 - f1: 0.8784 - val_loss: 0.0652 - val_acc: 0.8991 - val_auc: 0.9703 - val_f1: 0.8991\n",
      "Epoch 13/20\n",
      "57895/57895 [==============================] - 5s 81us/step - loss: 0.0752 - acc: 0.8825 - auc: 0.9615 - f1: 0.8825 - val_loss: 0.0720 - val_acc: 0.8937 - val_auc: 0.9656 - val_f1: 0.8937\n",
      "Epoch 14/20\n",
      "57895/57895 [==============================] - 5s 82us/step - loss: 0.0736 - acc: 0.8860 - auc: 0.9635 - f1: 0.8860 - val_loss: 0.0651 - val_acc: 0.9026 - val_auc: 0.9708 - val_f1: 0.9026\n",
      "Epoch 15/20\n",
      "57895/57895 [==============================] - 5s 82us/step - loss: 0.0695 - acc: 0.8911 - auc: 0.9674 - f1: 0.8911 - val_loss: 0.0604 - val_acc: 0.9123 - val_auc: 0.9744 - val_f1: 0.9123\n",
      "Epoch 16/20\n",
      "57895/57895 [==============================] - 5s 80us/step - loss: 0.0683 - acc: 0.8936 - auc: 0.9681 - f1: 0.8936 - val_loss: 0.0597 - val_acc: 0.9136 - val_auc: 0.9751 - val_f1: 0.9136\n",
      "Epoch 17/20\n",
      "57895/57895 [==============================] - 5s 85us/step - loss: 0.0673 - acc: 0.8938 - auc: 0.9693 - f1: 0.8938 - val_loss: 0.0626 - val_acc: 0.9038 - val_auc: 0.9730 - val_f1: 0.9038\n",
      "Epoch 18/20\n",
      "57895/57895 [==============================] - 5s 90us/step - loss: 0.0662 - acc: 0.8969 - auc: 0.9697 - f1: 0.8969 - val_loss: 0.0592 - val_acc: 0.9092 - val_auc: 0.9751 - val_f1: 0.9092\n",
      "Epoch 19/20\n",
      "57895/57895 [==============================] - 5s 90us/step - loss: 0.0660 - acc: 0.8969 - auc: 0.9702 - f1: 0.8969 - val_loss: 0.0582 - val_acc: 0.9104 - val_auc: 0.9763 - val_f1: 0.9104\n",
      "Epoch 20/20\n",
      "57895/57895 [==============================] - 5s 90us/step - loss: 0.0637 - acc: 0.9020 - auc: 0.9720 - f1: 0.9020 - val_loss: 0.0572 - val_acc: 0.9153 - val_auc: 0.9769 - val_f1: 0.9153\n",
      "[[ 2632   141]\n",
      " [ 1085 10615]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.95      0.81      2773\n",
      "           1       0.99      0.91      0.95     11700\n",
      "\n",
      "    accuracy                           0.92     14473\n",
      "   macro avg       0.85      0.93      0.88     14473\n",
      "weighted avg       0.93      0.92      0.92     14473\n",
      "\n",
      "time (in seconds) 505.87783455848694\n",
      "... DONE!\n",
      "... DONE!\n",
      "window_size: 5\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (96505, 8, 5)\n",
      "tensor input y: (96505, 2)\n",
      "proportion of y labels: (array([0, 1]), array([19275, 77230]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (67553, 5, 8)\n",
      "Tensor y train: (67553, 2)\n",
      "Tensor X test: (28952, 5, 8)\n",
      "Tensor y test: (28952, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (5, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_46 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_47 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_48 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54042 samples, validate on 13511 samples\n",
      "Epoch 1/20\n",
      "54042/54042 [==============================] - 9s 163us/step - loss: 0.1768 - acc: 0.7013 - auc: 0.7890 - f1: 0.7013 - val_loss: 0.1644 - val_acc: 0.7153 - val_auc: 0.8232 - val_f1: 0.7153\n",
      "Epoch 2/20\n",
      "54042/54042 [==============================] - 5s 96us/step - loss: 0.1668 - acc: 0.7156 - auc: 0.8179 - f1: 0.7156 - val_loss: 0.1605 - val_acc: 0.7033 - val_auc: 0.8294 - val_f1: 0.7033\n",
      "Epoch 3/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.1626 - acc: 0.7208 - auc: 0.8245 - f1: 0.7208 - val_loss: 0.1625 - val_acc: 0.6649 - val_auc: 0.8389 - val_f1: 0.6649\n",
      "Epoch 4/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.1552 - acc: 0.7349 - auc: 0.8438 - f1: 0.7349 - val_loss: 0.1450 - val_acc: 0.7649 - val_auc: 0.8638 - val_f1: 0.7649\n",
      "Epoch 5/20\n",
      "54042/54042 [==============================] - 5s 99us/step - loss: 0.1418 - acc: 0.7662 - auc: 0.8713 - f1: 0.7662 - val_loss: 0.1252 - val_acc: 0.7798 - val_auc: 0.8995 - val_f1: 0.7798\n",
      "Epoch 6/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.1213 - acc: 0.8039 - auc: 0.9070 - f1: 0.8039 - val_loss: 0.1026 - val_acc: 0.8287 - val_auc: 0.9375 - val_f1: 0.8287\n",
      "Epoch 7/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.1031 - acc: 0.8420 - auc: 0.9339 - f1: 0.8420 - val_loss: 0.0812 - val_acc: 0.8695 - val_auc: 0.9583 - val_f1: 0.8695\n",
      "Epoch 8/20\n",
      "54042/54042 [==============================] - 5s 99us/step - loss: 0.0879 - acc: 0.8655 - auc: 0.9509 - f1: 0.8655 - val_loss: 0.0695 - val_acc: 0.8905 - val_auc: 0.9685 - val_f1: 0.8905\n",
      "Epoch 9/20\n",
      "54042/54042 [==============================] - 5s 99us/step - loss: 0.0832 - acc: 0.8747 - auc: 0.9564 - f1: 0.8747 - val_loss: 0.0738 - val_acc: 0.8879 - val_auc: 0.9654 - val_f1: 0.8879\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.0788 - acc: 0.8789 - auc: 0.9604 - f1: 0.8789 - val_loss: 0.0670 - val_acc: 0.8988 - val_auc: 0.9705 - val_f1: 0.8988\n",
      "Epoch 11/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.0732 - acc: 0.8892 - auc: 0.9658 - f1: 0.8892 - val_loss: 0.0630 - val_acc: 0.9090 - val_auc: 0.9737 - val_f1: 0.9090\n",
      "Epoch 12/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.0733 - acc: 0.8880 - auc: 0.9661 - f1: 0.8880 - val_loss: 0.0746 - val_acc: 0.8962 - val_auc: 0.9663 - val_f1: 0.8962\n",
      "Epoch 13/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.0687 - acc: 0.8976 - auc: 0.9692 - f1: 0.8976 - val_loss: 0.0562 - val_acc: 0.9170 - val_auc: 0.9780 - val_f1: 0.9170\n",
      "Epoch 14/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.0649 - acc: 0.9024 - auc: 0.9721 - f1: 0.9024 - val_loss: 0.0596 - val_acc: 0.9193 - val_auc: 0.9768 - val_f1: 0.9193\n",
      "Epoch 15/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0661 - acc: 0.9029 - auc: 0.9716 - f1: 0.9029 - val_loss: 0.0570 - val_acc: 0.9234 - val_auc: 0.9783 - val_f1: 0.9234\n",
      "Epoch 16/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.0645 - acc: 0.9058 - auc: 0.9728 - f1: 0.9058 - val_loss: 0.0526 - val_acc: 0.9232 - val_auc: 0.9807 - val_f1: 0.9232\n",
      "Epoch 17/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.0626 - acc: 0.9072 - auc: 0.9745 - f1: 0.9072 - val_loss: 0.0548 - val_acc: 0.9152 - val_auc: 0.9797 - val_f1: 0.9152\n",
      "Epoch 18/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.0608 - acc: 0.9119 - auc: 0.9755 - f1: 0.9119 - val_loss: 0.0552 - val_acc: 0.9210 - val_auc: 0.9795 - val_f1: 0.9210\n",
      "Epoch 19/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0590 - acc: 0.9135 - auc: 0.9768 - f1: 0.9135 - val_loss: 0.0516 - val_acc: 0.9264 - val_auc: 0.9811 - val_f1: 0.9264\n",
      "Epoch 20/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0573 - acc: 0.9174 - auc: 0.9777 - f1: 0.9174 - val_loss: 0.0540 - val_acc: 0.9292 - val_auc: 0.9803 - val_f1: 0.9292\n",
      "[[ 2520   164]\n",
      " [  792 10035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      2684\n",
      "           1       0.98      0.93      0.95     10827\n",
      "\n",
      "    accuracy                           0.93     13511\n",
      "   macro avg       0.87      0.93      0.90     13511\n",
      "weighted avg       0.94      0.93      0.93     13511\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (5, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_49 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_50 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_51 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54042 samples, validate on 13511 samples\n",
      "Epoch 1/20\n",
      "54042/54042 [==============================] - 9s 170us/step - loss: 0.1763 - acc: 0.7034 - auc: 0.7903 - f1: 0.7034 - val_loss: 0.1684 - val_acc: 0.7246 - val_auc: 0.8139 - val_f1: 0.7246\n",
      "Epoch 2/20\n",
      "54042/54042 [==============================] - 6s 104us/step - loss: 0.1662 - acc: 0.7126 - auc: 0.8177 - f1: 0.7126 - val_loss: 0.1620 - val_acc: 0.7237 - val_auc: 0.8265 - val_f1: 0.7237\n",
      "Epoch 3/20\n",
      "54042/54042 [==============================] - 6s 103us/step - loss: 0.1618 - acc: 0.7235 - auc: 0.8276 - f1: 0.7235 - val_loss: 0.1583 - val_acc: 0.7378 - val_auc: 0.8344 - val_f1: 0.7378\n",
      "Epoch 4/20\n",
      "54042/54042 [==============================] - 6s 103us/step - loss: 0.1550 - acc: 0.7374 - auc: 0.8427 - f1: 0.7374 - val_loss: 0.1467 - val_acc: 0.7688 - val_auc: 0.8610 - val_f1: 0.7688\n",
      "Epoch 5/20\n",
      "54042/54042 [==============================] - 6s 103us/step - loss: 0.1435 - acc: 0.7645 - auc: 0.8683 - f1: 0.7645 - val_loss: 0.1341 - val_acc: 0.7449 - val_auc: 0.8902 - val_f1: 0.7449\n",
      "Epoch 6/20\n",
      "54042/54042 [==============================] - 5s 102us/step - loss: 0.1301 - acc: 0.7906 - auc: 0.8945 - f1: 0.7906 - val_loss: 0.1163 - val_acc: 0.8242 - val_auc: 0.9153 - val_f1: 0.8242\n",
      "Epoch 7/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.1148 - acc: 0.8213 - auc: 0.9184 - f1: 0.8213 - val_loss: 0.0985 - val_acc: 0.8569 - val_auc: 0.9390 - val_f1: 0.8569\n",
      "Epoch 8/20\n",
      "54042/54042 [==============================] - 5s 102us/step - loss: 0.1009 - acc: 0.8459 - auc: 0.9371 - f1: 0.8459 - val_loss: 0.0869 - val_acc: 0.8588 - val_auc: 0.9521 - val_f1: 0.8588\n",
      "Epoch 9/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0904 - acc: 0.8615 - auc: 0.9490 - f1: 0.8615 - val_loss: 0.0802 - val_acc: 0.8929 - val_auc: 0.9606 - val_f1: 0.8929\n",
      "Epoch 10/20\n",
      "54042/54042 [==============================] - 6s 102us/step - loss: 0.0838 - acc: 0.8727 - auc: 0.9562 - f1: 0.8727 - val_loss: 0.0766 - val_acc: 0.8946 - val_auc: 0.9630 - val_f1: 0.8946\n",
      "Epoch 11/20\n",
      "54042/54042 [==============================] - 6s 102us/step - loss: 0.0796 - acc: 0.8783 - auc: 0.9599 - f1: 0.8783 - val_loss: 0.0692 - val_acc: 0.9011 - val_auc: 0.9682 - val_f1: 0.9011\n",
      "Epoch 12/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0760 - acc: 0.8843 - auc: 0.9633 - f1: 0.8843 - val_loss: 0.0676 - val_acc: 0.8805 - val_auc: 0.9694 - val_f1: 0.8805\n",
      "Epoch 13/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0729 - acc: 0.8872 - auc: 0.9660 - f1: 0.8872 - val_loss: 0.0669 - val_acc: 0.9042 - val_auc: 0.9704 - val_f1: 0.9042\n",
      "Epoch 14/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0711 - acc: 0.8919 - auc: 0.9672 - f1: 0.8919 - val_loss: 0.0639 - val_acc: 0.9079 - val_auc: 0.9726 - val_f1: 0.9079\n",
      "Epoch 15/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0679 - acc: 0.8972 - auc: 0.9700 - f1: 0.8972 - val_loss: 0.0616 - val_acc: 0.9020 - val_auc: 0.9741 - val_f1: 0.9020\n",
      "Epoch 16/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0667 - acc: 0.9006 - auc: 0.9711 - f1: 0.9006 - val_loss: 0.0586 - val_acc: 0.9124 - val_auc: 0.9766 - val_f1: 0.9124\n",
      "Epoch 17/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0631 - acc: 0.9046 - auc: 0.9738 - f1: 0.9046 - val_loss: 0.0704 - val_acc: 0.9151 - val_auc: 0.9719 - val_f1: 0.9151\n",
      "Epoch 18/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0642 - acc: 0.9041 - auc: 0.9731 - f1: 0.9041 - val_loss: 0.0552 - val_acc: 0.9165 - val_auc: 0.9790 - val_f1: 0.9165\n",
      "Epoch 19/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0622 - acc: 0.9079 - auc: 0.9748 - f1: 0.9079 - val_loss: 0.0577 - val_acc: 0.9261 - val_auc: 0.9780 - val_f1: 0.9261\n",
      "Epoch 20/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.0615 - acc: 0.9091 - auc: 0.9748 - f1: 0.9091 - val_loss: 0.0575 - val_acc: 0.9234 - val_auc: 0.9780 - val_f1: 0.9234\n",
      "[[2503  181]\n",
      " [ 854 9973]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      2684\n",
      "           1       0.98      0.92      0.95     10827\n",
      "\n",
      "    accuracy                           0.92     13511\n",
      "   macro avg       0.86      0.93      0.89     13511\n",
      "weighted avg       0.94      0.92      0.93     13511\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (5, 8) 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_52 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_53 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_54 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54042 samples, validate on 13511 samples\n",
      "Epoch 1/20\n",
      "54042/54042 [==============================] - 9s 174us/step - loss: 0.1794 - acc: 0.6934 - auc: 0.7849 - f1: 0.6934 - val_loss: 0.1683 - val_acc: 0.7488 - val_auc: 0.8179 - val_f1: 0.7488\n",
      "Epoch 2/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.1667 - acc: 0.7100 - auc: 0.8161 - f1: 0.7100 - val_loss: 0.1623 - val_acc: 0.7187 - val_auc: 0.8278 - val_f1: 0.7187\n",
      "Epoch 3/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.1621 - acc: 0.7161 - auc: 0.8262 - f1: 0.7161 - val_loss: 0.1604 - val_acc: 0.7173 - val_auc: 0.8344 - val_f1: 0.7173\n",
      "Epoch 4/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.1556 - acc: 0.7299 - auc: 0.8417 - f1: 0.7299 - val_loss: 0.1476 - val_acc: 0.7643 - val_auc: 0.8614 - val_f1: 0.7643\n",
      "Epoch 5/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.1413 - acc: 0.7615 - auc: 0.8716 - f1: 0.7615 - val_loss: 0.1312 - val_acc: 0.7979 - val_auc: 0.8928 - val_f1: 0.7979\n",
      "Epoch 6/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.1235 - acc: 0.7978 - auc: 0.9043 - f1: 0.7978 - val_loss: 0.1032 - val_acc: 0.8483 - val_auc: 0.9339 - val_f1: 0.8483\n",
      "Epoch 7/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.1039 - acc: 0.8387 - auc: 0.9328 - f1: 0.8387 - val_loss: 0.0954 - val_acc: 0.8725 - val_auc: 0.9452 - val_f1: 0.8725\n",
      "Epoch 8/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0917 - acc: 0.8616 - auc: 0.9477 - f1: 0.8616 - val_loss: 0.0806 - val_acc: 0.8934 - val_auc: 0.9592 - val_f1: 0.8934\n",
      "Epoch 9/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0843 - acc: 0.8748 - auc: 0.9558 - f1: 0.8748 - val_loss: 0.0751 - val_acc: 0.8975 - val_auc: 0.9646 - val_f1: 0.8975\n",
      "Epoch 10/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0766 - acc: 0.8865 - auc: 0.9630 - f1: 0.8865 - val_loss: 0.0681 - val_acc: 0.9133 - val_auc: 0.9708 - val_f1: 0.9133\n",
      "Epoch 11/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0730 - acc: 0.8922 - auc: 0.9665 - f1: 0.8922 - val_loss: 0.0633 - val_acc: 0.9050 - val_auc: 0.9731 - val_f1: 0.9050\n",
      "Epoch 12/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0689 - acc: 0.8996 - auc: 0.9698 - f1: 0.8996 - val_loss: 0.0669 - val_acc: 0.9129 - val_auc: 0.9719 - val_f1: 0.9129\n",
      "Epoch 13/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0674 - acc: 0.9008 - auc: 0.9709 - f1: 0.9008 - val_loss: 0.0609 - val_acc: 0.9212 - val_auc: 0.9757 - val_f1: 0.9212\n",
      "Epoch 14/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0664 - acc: 0.9031 - auc: 0.9718 - f1: 0.9031 - val_loss: 0.0589 - val_acc: 0.9186 - val_auc: 0.9764 - val_f1: 0.9186\n",
      "Epoch 15/20\n",
      "54042/54042 [==============================] - 5s 99us/step - loss: 0.0638 - acc: 0.9068 - auc: 0.9737 - f1: 0.9068 - val_loss: 0.0588 - val_acc: 0.9197 - val_auc: 0.9774 - val_f1: 0.9197\n",
      "Epoch 16/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.0624 - acc: 0.9093 - auc: 0.9746 - f1: 0.9093 - val_loss: 0.0568 - val_acc: 0.9197 - val_auc: 0.9778 - val_f1: 0.9197\n",
      "Epoch 17/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.0628 - acc: 0.9072 - auc: 0.9750 - f1: 0.9072 - val_loss: 0.0588 - val_acc: 0.9238 - val_auc: 0.9774 - val_f1: 0.9238\n",
      "Epoch 18/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.0618 - acc: 0.9120 - auc: 0.9754 - f1: 0.9120 - val_loss: 0.0577 - val_acc: 0.9130 - val_auc: 0.9781 - val_f1: 0.9130\n",
      "Epoch 19/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.0593 - acc: 0.9123 - auc: 0.9773 - f1: 0.9123 - val_loss: 0.0586 - val_acc: 0.9229 - val_auc: 0.9771 - val_f1: 0.9229\n",
      "Epoch 20/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.0590 - acc: 0.9139 - auc: 0.9774 - f1: 0.9139 - val_loss: 0.0601 - val_acc: 0.9174 - val_auc: 0.9768 - val_f1: 0.9174\n",
      "[[2533  151]\n",
      " [ 965 9862]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82      2684\n",
      "           1       0.98      0.91      0.95     10827\n",
      "\n",
      "    accuracy                           0.92     13511\n",
      "   macro avg       0.85      0.93      0.88     13511\n",
      "weighted avg       0.93      0.92      0.92     13511\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (5, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_55 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_56 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_57 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54042 samples, validate on 13511 samples\n",
      "Epoch 1/20\n",
      "54042/54042 [==============================] - 10s 179us/step - loss: 0.1798 - acc: 0.6948 - auc: 0.7826 - f1: 0.6948 - val_loss: 0.1689 - val_acc: 0.6757 - val_auc: 0.8197 - val_f1: 0.6757\n",
      "Epoch 2/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.1678 - acc: 0.7116 - auc: 0.8149 - f1: 0.7116 - val_loss: 0.1619 - val_acc: 0.6871 - val_auc: 0.8262 - val_f1: 0.6871\n",
      "Epoch 3/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.1630 - acc: 0.7176 - auc: 0.8244 - f1: 0.7176 - val_loss: 0.1579 - val_acc: 0.7296 - val_auc: 0.8347 - val_f1: 0.7296\n",
      "Epoch 4/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.1568 - acc: 0.7361 - auc: 0.8385 - f1: 0.7361 - val_loss: 0.1504 - val_acc: 0.7791 - val_auc: 0.8590 - val_f1: 0.7791\n",
      "Epoch 5/20\n",
      "54042/54042 [==============================] - 5s 101us/step - loss: 0.1459 - acc: 0.7591 - auc: 0.8635 - f1: 0.7591 - val_loss: 0.1297 - val_acc: 0.8011 - val_auc: 0.8942 - val_f1: 0.8011\n",
      "Epoch 6/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.1314 - acc: 0.7885 - auc: 0.8928 - f1: 0.7885 - val_loss: 0.1176 - val_acc: 0.8425 - val_auc: 0.9189 - val_f1: 0.8425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.1134 - acc: 0.8236 - auc: 0.9202 - f1: 0.8236 - val_loss: 0.0967 - val_acc: 0.8654 - val_auc: 0.9433 - val_f1: 0.8654\n",
      "Epoch 8/20\n",
      "54042/54042 [==============================] - 5s 100us/step - loss: 0.1003 - acc: 0.8482 - auc: 0.9374 - f1: 0.8482 - val_loss: 0.0916 - val_acc: 0.8520 - val_auc: 0.9496 - val_f1: 0.8520\n",
      "Epoch 9/20\n",
      "54042/54042 [==============================] - 5s 99us/step - loss: 0.0895 - acc: 0.8608 - auc: 0.9493 - f1: 0.8608 - val_loss: 0.0812 - val_acc: 0.8848 - val_auc: 0.9601 - val_f1: 0.8848\n",
      "Epoch 10/20\n",
      "54042/54042 [==============================] - 5s 97us/step - loss: 0.0846 - acc: 0.8679 - auc: 0.9549 - f1: 0.8679 - val_loss: 0.0731 - val_acc: 0.8842 - val_auc: 0.9666 - val_f1: 0.8842\n",
      "Epoch 11/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0786 - acc: 0.8798 - auc: 0.9606 - f1: 0.8798 - val_loss: 0.0689 - val_acc: 0.8987 - val_auc: 0.9699 - val_f1: 0.8987\n",
      "Epoch 12/20\n",
      "54042/54042 [==============================] - 5s 99us/step - loss: 0.0742 - acc: 0.8857 - auc: 0.9648 - f1: 0.8857 - val_loss: 0.0671 - val_acc: 0.9027 - val_auc: 0.9718 - val_f1: 0.9027\n",
      "Epoch 13/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0716 - acc: 0.8898 - auc: 0.9666 - f1: 0.8898 - val_loss: 0.0630 - val_acc: 0.9144 - val_auc: 0.9745 - val_f1: 0.9144\n",
      "Epoch 14/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0703 - acc: 0.8928 - auc: 0.9679 - f1: 0.8928 - val_loss: 0.0643 - val_acc: 0.9198 - val_auc: 0.9742 - val_f1: 0.9198\n",
      "Epoch 15/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0683 - acc: 0.8964 - auc: 0.9700 - f1: 0.8964 - val_loss: 0.0646 - val_acc: 0.9204 - val_auc: 0.9750 - val_f1: 0.9204\n",
      "Epoch 16/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0648 - acc: 0.9035 - auc: 0.9725 - f1: 0.9035 - val_loss: 0.0617 - val_acc: 0.9127 - val_auc: 0.9747 - val_f1: 0.9127\n",
      "Epoch 17/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0663 - acc: 0.9006 - auc: 0.9711 - f1: 0.9006 - val_loss: 0.0665 - val_acc: 0.9264 - val_auc: 0.9747 - val_f1: 0.9264\n",
      "Epoch 18/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0621 - acc: 0.9084 - auc: 0.9747 - f1: 0.9084 - val_loss: 0.0591 - val_acc: 0.9174 - val_auc: 0.9776 - val_f1: 0.9174\n",
      "Epoch 19/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0632 - acc: 0.9050 - auc: 0.9736 - f1: 0.9050 - val_loss: 0.0577 - val_acc: 0.9228 - val_auc: 0.9780 - val_f1: 0.9228\n",
      "Epoch 20/20\n",
      "54042/54042 [==============================] - 5s 98us/step - loss: 0.0611 - acc: 0.9107 - auc: 0.9752 - f1: 0.9107 - val_loss: 0.0574 - val_acc: 0.9179 - val_auc: 0.9790 - val_f1: 0.9179\n",
      "[[2547  137]\n",
      " [ 972 9855]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82      2684\n",
      "           1       0.99      0.91      0.95     10827\n",
      "\n",
      "    accuracy                           0.92     13511\n",
      "   macro avg       0.86      0.93      0.88     13511\n",
      "weighted avg       0.93      0.92      0.92     13511\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (5, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_58 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_59 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_60 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54044 samples, validate on 13509 samples\n",
      "Epoch 1/20\n",
      "54044/54044 [==============================] - 10s 184us/step - loss: 0.1794 - acc: 0.6966 - auc: 0.7851 - f1: 0.6966 - val_loss: 0.1649 - val_acc: 0.7442 - val_auc: 0.8214 - val_f1: 0.7442\n",
      "Epoch 2/20\n",
      "54044/54044 [==============================] - 5s 99us/step - loss: 0.1664 - acc: 0.7162 - auc: 0.8159 - f1: 0.7162 - val_loss: 0.1614 - val_acc: 0.7185 - val_auc: 0.8289 - val_f1: 0.7185\n",
      "Epoch 3/20\n",
      "54044/54044 [==============================] - 5s 99us/step - loss: 0.1629 - acc: 0.7201 - auc: 0.8253 - f1: 0.7201 - val_loss: 0.1534 - val_acc: 0.7428 - val_auc: 0.8463 - val_f1: 0.7428\n",
      "Epoch 4/20\n",
      "54044/54044 [==============================] - 5s 98us/step - loss: 0.1546 - acc: 0.7384 - auc: 0.8455 - f1: 0.7384 - val_loss: 0.1401 - val_acc: 0.7753 - val_auc: 0.8720 - val_f1: 0.7753\n",
      "Epoch 5/20\n",
      "54044/54044 [==============================] - 5s 98us/step - loss: 0.1414 - acc: 0.7654 - auc: 0.8728 - f1: 0.7654 - val_loss: 0.1246 - val_acc: 0.7855 - val_auc: 0.9004 - val_f1: 0.7855\n",
      "Epoch 6/20\n",
      "54044/54044 [==============================] - 5s 98us/step - loss: 0.1245 - acc: 0.7975 - auc: 0.9035 - f1: 0.7975 - val_loss: 0.1030 - val_acc: 0.8284 - val_auc: 0.9330 - val_f1: 0.8284\n",
      "Epoch 7/20\n",
      "54044/54044 [==============================] - 5s 98us/step - loss: 0.1048 - acc: 0.8353 - auc: 0.9322 - f1: 0.8353 - val_loss: 0.0881 - val_acc: 0.8768 - val_auc: 0.9528 - val_f1: 0.8768\n",
      "Epoch 8/20\n",
      "54044/54044 [==============================] - 5s 98us/step - loss: 0.0938 - acc: 0.8561 - auc: 0.9454 - f1: 0.8561 - val_loss: 0.0801 - val_acc: 0.8879 - val_auc: 0.9598 - val_f1: 0.8879\n",
      "Epoch 9/20\n",
      "54044/54044 [==============================] - 5s 99us/step - loss: 0.0863 - acc: 0.8649 - auc: 0.9531 - f1: 0.8649 - val_loss: 0.0714 - val_acc: 0.8877 - val_auc: 0.9665 - val_f1: 0.8877\n",
      "Epoch 10/20\n",
      "54044/54044 [==============================] - 5s 99us/step - loss: 0.0779 - acc: 0.8794 - auc: 0.9613 - f1: 0.8794 - val_loss: 0.0711 - val_acc: 0.9013 - val_auc: 0.9687 - val_f1: 0.9013\n",
      "Epoch 11/20\n",
      "54044/54044 [==============================] - 5s 98us/step - loss: 0.0743 - acc: 0.8872 - auc: 0.9649 - f1: 0.8872 - val_loss: 0.0632 - val_acc: 0.9041 - val_auc: 0.9737 - val_f1: 0.9041\n",
      "Epoch 12/20\n",
      "54044/54044 [==============================] - 5s 99us/step - loss: 0.0714 - acc: 0.8936 - auc: 0.9673 - f1: 0.8936 - val_loss: 0.0616 - val_acc: 0.9197 - val_auc: 0.9755 - val_f1: 0.9197\n",
      "Epoch 13/20\n",
      "54044/54044 [==============================] - 5s 101us/step - loss: 0.0671 - acc: 0.8995 - auc: 0.9702 - f1: 0.8995 - val_loss: 0.0587 - val_acc: 0.9061 - val_auc: 0.9764 - val_f1: 0.9061\n",
      "Epoch 14/20\n",
      "54044/54044 [==============================] - 5s 100us/step - loss: 0.0650 - acc: 0.9028 - auc: 0.9718 - f1: 0.9028 - val_loss: 0.0648 - val_acc: 0.9214 - val_auc: 0.9744 - val_f1: 0.9214\n",
      "Epoch 15/20\n",
      "54044/54044 [==============================] - 5s 100us/step - loss: 0.0657 - acc: 0.9036 - auc: 0.9719 - f1: 0.9036 - val_loss: 0.0602 - val_acc: 0.9138 - val_auc: 0.9766 - val_f1: 0.9138\n",
      "Epoch 16/20\n",
      "54044/54044 [==============================] - 5s 101us/step - loss: 0.0647 - acc: 0.9051 - auc: 0.9727 - f1: 0.9051 - val_loss: 0.0554 - val_acc: 0.9168 - val_auc: 0.9796 - val_f1: 0.9168\n",
      "Epoch 17/20\n",
      "54044/54044 [==============================] - 5s 100us/step - loss: 0.0608 - acc: 0.9101 - auc: 0.9754 - f1: 0.9101 - val_loss: 0.0584 - val_acc: 0.9300 - val_auc: 0.9784 - val_f1: 0.9300\n",
      "Epoch 18/20\n",
      "54044/54044 [==============================] - 5s 100us/step - loss: 0.0597 - acc: 0.9134 - auc: 0.9762 - f1: 0.9134 - val_loss: 0.0536 - val_acc: 0.9355 - val_auc: 0.9813 - val_f1: 0.9355\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54044/54044 [==============================] - 5s 100us/step - loss: 0.0576 - acc: 0.9171 - auc: 0.9779 - f1: 0.9171 - val_loss: 0.0574 - val_acc: 0.9278 - val_auc: 0.9786 - val_f1: 0.9278\n",
      "Epoch 20/20\n",
      "54044/54044 [==============================] - 5s 100us/step - loss: 0.0566 - acc: 0.9185 - auc: 0.9784 - f1: 0.9185 - val_loss: 0.0558 - val_acc: 0.9360 - val_auc: 0.9812 - val_f1: 0.9360\n",
      "[[ 2500   183]\n",
      " [  681 10145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85      2683\n",
      "           1       0.98      0.94      0.96     10826\n",
      "\n",
      "    accuracy                           0.94     13509\n",
      "   macro avg       0.88      0.93      0.91     13509\n",
      "weighted avg       0.94      0.94      0.94     13509\n",
      "\n",
      "time (in seconds) 575.0116217136383\n",
      "... DONE!\n",
      "... DONE!\n",
      "window_size: 6\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (90199, 8, 6)\n",
      "tensor input y: (90199, 2)\n",
      "proportion of y labels: (array([0, 1]), array([17659, 72540]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (63139, 6, 8)\n",
      "Tensor y train: (63139, 2)\n",
      "Tensor X test: (27060, 6, 8)\n",
      "Tensor y test: (27060, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_61 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_62 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_63 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50511 samples, validate on 12628 samples\n",
      "Epoch 1/20\n",
      "50511/50511 [==============================] - 10s 207us/step - loss: 0.1775 - acc: 0.6997 - auc: 0.7873 - f1: 0.6997 - val_loss: 0.1674 - val_acc: 0.7240 - val_auc: 0.8101 - val_f1: 0.7240\n",
      "Epoch 2/20\n",
      "50511/50511 [==============================] - 6s 114us/step - loss: 0.1651 - acc: 0.7123 - auc: 0.8163 - f1: 0.7123 - val_loss: 0.1633 - val_acc: 0.7077 - val_auc: 0.8184 - val_f1: 0.7077\n",
      "Epoch 3/20\n",
      "50511/50511 [==============================] - 6s 116us/step - loss: 0.1619 - acc: 0.7177 - auc: 0.8234 - f1: 0.7177 - val_loss: 0.1636 - val_acc: 0.7338 - val_auc: 0.8233 - val_f1: 0.7338\n",
      "Epoch 4/20\n",
      "50511/50511 [==============================] - 6s 115us/step - loss: 0.1584 - acc: 0.7264 - auc: 0.8325 - f1: 0.7264 - val_loss: 0.1575 - val_acc: 0.7454 - val_auc: 0.8350 - val_f1: 0.7454\n",
      "Epoch 5/20\n",
      "50511/50511 [==============================] - 6s 116us/step - loss: 0.1508 - acc: 0.7443 - auc: 0.8501 - f1: 0.7443 - val_loss: 0.1420 - val_acc: 0.7452 - val_auc: 0.8695 - val_f1: 0.7452\n",
      "Epoch 6/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1397 - acc: 0.7659 - auc: 0.8744 - f1: 0.7659 - val_loss: 0.1290 - val_acc: 0.7984 - val_auc: 0.8924 - val_f1: 0.7984\n",
      "Epoch 7/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1261 - acc: 0.7959 - auc: 0.8981 - f1: 0.7959 - val_loss: 0.1110 - val_acc: 0.8218 - val_auc: 0.9207 - val_f1: 0.8218\n",
      "Epoch 8/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1073 - acc: 0.8299 - auc: 0.9264 - f1: 0.8299 - val_loss: 0.0923 - val_acc: 0.8628 - val_auc: 0.9447 - val_f1: 0.8628\n",
      "Epoch 9/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0932 - acc: 0.8558 - auc: 0.9446 - f1: 0.8558 - val_loss: 0.0834 - val_acc: 0.8884 - val_auc: 0.9578 - val_f1: 0.8884\n",
      "Epoch 10/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0850 - acc: 0.8697 - auc: 0.9531 - f1: 0.8697 - val_loss: 0.0737 - val_acc: 0.8774 - val_auc: 0.9648 - val_f1: 0.8774\n",
      "Epoch 11/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0770 - acc: 0.8799 - auc: 0.9612 - f1: 0.8799 - val_loss: 0.0705 - val_acc: 0.9017 - val_auc: 0.9689 - val_f1: 0.9017\n",
      "Epoch 12/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0742 - acc: 0.8869 - auc: 0.9637 - f1: 0.8869 - val_loss: 0.0673 - val_acc: 0.8898 - val_auc: 0.9712 - val_f1: 0.8898\n",
      "Epoch 13/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0712 - acc: 0.8925 - auc: 0.9668 - f1: 0.8925 - val_loss: 0.0659 - val_acc: 0.9009 - val_auc: 0.9715 - val_f1: 0.9009\n",
      "Epoch 14/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0693 - acc: 0.8926 - auc: 0.9684 - f1: 0.8926 - val_loss: 0.0602 - val_acc: 0.8973 - val_auc: 0.9767 - val_f1: 0.8973\n",
      "Epoch 15/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0665 - acc: 0.8987 - auc: 0.9708 - f1: 0.8987 - val_loss: 0.0624 - val_acc: 0.9029 - val_auc: 0.9738 - val_f1: 0.9029\n",
      "Epoch 16/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0635 - acc: 0.9014 - auc: 0.9728 - f1: 0.9014 - val_loss: 0.0580 - val_acc: 0.9014 - val_auc: 0.9785 - val_f1: 0.9014\n",
      "Epoch 17/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0608 - acc: 0.9065 - auc: 0.9750 - f1: 0.9065 - val_loss: 0.0580 - val_acc: 0.9092 - val_auc: 0.9780 - val_f1: 0.9092\n",
      "Epoch 18/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0616 - acc: 0.9060 - auc: 0.9747 - f1: 0.9060 - val_loss: 0.0611 - val_acc: 0.9013 - val_auc: 0.9764 - val_f1: 0.9013\n",
      "Epoch 19/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0606 - acc: 0.9072 - auc: 0.9755 - f1: 0.9072 - val_loss: 0.0561 - val_acc: 0.9257 - val_auc: 0.9801 - val_f1: 0.9257\n",
      "Epoch 20/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0573 - acc: 0.9122 - auc: 0.9775 - f1: 0.9122 - val_loss: 0.0619 - val_acc: 0.9279 - val_auc: 0.9782 - val_f1: 0.9279\n",
      "[[2287  195]\n",
      " [ 716 9430]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83      2482\n",
      "           1       0.98      0.93      0.95     10146\n",
      "\n",
      "    accuracy                           0.93     12628\n",
      "   macro avg       0.87      0.93      0.89     12628\n",
      "weighted avg       0.94      0.93      0.93     12628\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_64 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_65 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_66 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50511 samples, validate on 12628 samples\n",
      "Epoch 1/20\n",
      "50511/50511 [==============================] - 11s 216us/step - loss: 0.1778 - acc: 0.6962 - auc: 0.7822 - f1: 0.6962 - val_loss: 0.1638 - val_acc: 0.7627 - val_auc: 0.8242 - val_f1: 0.7627\n",
      "Epoch 2/20\n",
      "50511/50511 [==============================] - 6s 116us/step - loss: 0.1664 - acc: 0.7094 - auc: 0.8143 - f1: 0.7094 - val_loss: 0.1578 - val_acc: 0.7001 - val_auc: 0.8342 - val_f1: 0.7001\n",
      "Epoch 3/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.1629 - acc: 0.7177 - auc: 0.8230 - f1: 0.7177 - val_loss: 0.1563 - val_acc: 0.7582 - val_auc: 0.8377 - val_f1: 0.7582\n",
      "Epoch 4/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.1582 - acc: 0.7256 - auc: 0.8338 - f1: 0.7256 - val_loss: 0.1466 - val_acc: 0.7536 - val_auc: 0.8578 - val_f1: 0.7536\n",
      "Epoch 5/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.1454 - acc: 0.7561 - auc: 0.8628 - f1: 0.7561 - val_loss: 0.1351 - val_acc: 0.7905 - val_auc: 0.8814 - val_f1: 0.7905\n",
      "Epoch 6/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.1326 - acc: 0.7764 - auc: 0.8871 - f1: 0.7764 - val_loss: 0.1193 - val_acc: 0.8202 - val_auc: 0.9100 - val_f1: 0.8202\n",
      "Epoch 7/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.1149 - acc: 0.8135 - auc: 0.9159 - f1: 0.8135 - val_loss: 0.0970 - val_acc: 0.8478 - val_auc: 0.9394 - val_f1: 0.8478\n",
      "Epoch 8/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0981 - acc: 0.8430 - auc: 0.9392 - f1: 0.8430 - val_loss: 0.0868 - val_acc: 0.8605 - val_auc: 0.9514 - val_f1: 0.8605\n",
      "Epoch 9/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0880 - acc: 0.8617 - auc: 0.9507 - f1: 0.8617 - val_loss: 0.0751 - val_acc: 0.8836 - val_auc: 0.9631 - val_f1: 0.8836\n",
      "Epoch 10/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0804 - acc: 0.8744 - auc: 0.9590 - f1: 0.8744 - val_loss: 0.0767 - val_acc: 0.8988 - val_auc: 0.9643 - val_f1: 0.8988\n",
      "Epoch 11/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0756 - acc: 0.8821 - auc: 0.9636 - f1: 0.8821 - val_loss: 0.0741 - val_acc: 0.8877 - val_auc: 0.9638 - val_f1: 0.8877\n",
      "Epoch 12/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0745 - acc: 0.8854 - auc: 0.9641 - f1: 0.8854 - val_loss: 0.0711 - val_acc: 0.9009 - val_auc: 0.9689 - val_f1: 0.9009\n",
      "Epoch 13/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0689 - acc: 0.8927 - auc: 0.9687 - f1: 0.8927 - val_loss: 0.0673 - val_acc: 0.9107 - val_auc: 0.9722 - val_f1: 0.9107\n",
      "Epoch 14/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0671 - acc: 0.8976 - auc: 0.9704 - f1: 0.8976 - val_loss: 0.0618 - val_acc: 0.9089 - val_auc: 0.9744 - val_f1: 0.9089\n",
      "Epoch 15/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0656 - acc: 0.8998 - auc: 0.9717 - f1: 0.8998 - val_loss: 0.0664 - val_acc: 0.9032 - val_auc: 0.9713 - val_f1: 0.9032\n",
      "Epoch 16/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0632 - acc: 0.9051 - auc: 0.9735 - f1: 0.9051 - val_loss: 0.0607 - val_acc: 0.9126 - val_auc: 0.9756 - val_f1: 0.9126\n",
      "Epoch 17/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0616 - acc: 0.9060 - auc: 0.9744 - f1: 0.9060 - val_loss: 0.0651 - val_acc: 0.9214 - val_auc: 0.9756 - val_f1: 0.9214\n",
      "Epoch 18/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0601 - acc: 0.9081 - auc: 0.9757 - f1: 0.9081 - val_loss: 0.0628 - val_acc: 0.8994 - val_auc: 0.9750 - val_f1: 0.8994\n",
      "Epoch 19/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0580 - acc: 0.9129 - auc: 0.9770 - f1: 0.9129 - val_loss: 0.0610 - val_acc: 0.9189 - val_auc: 0.9766 - val_f1: 0.9189\n",
      "Epoch 20/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0578 - acc: 0.9105 - auc: 0.9770 - f1: 0.9105 - val_loss: 0.0623 - val_acc: 0.9010 - val_auc: 0.9744 - val_f1: 0.9010\n",
      "[[2347  135]\n",
      " [1115 9031]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.95      0.79      2482\n",
      "           1       0.99      0.89      0.94     10146\n",
      "\n",
      "    accuracy                           0.90     12628\n",
      "   macro avg       0.83      0.92      0.86     12628\n",
      "weighted avg       0.92      0.90      0.91     12628\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_67 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_68 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_69 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50511 samples, validate on 12628 samples\n",
      "Epoch 1/20\n",
      "50511/50511 [==============================] - 11s 223us/step - loss: 0.1766 - acc: 0.7004 - auc: 0.7871 - f1: 0.7004 - val_loss: 0.1636 - val_acc: 0.7033 - val_auc: 0.8194 - val_f1: 0.7033\n",
      "Epoch 2/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1661 - acc: 0.7098 - auc: 0.8152 - f1: 0.7098 - val_loss: 0.1647 - val_acc: 0.6608 - val_auc: 0.8309 - val_f1: 0.6608\n",
      "Epoch 3/20\n",
      "50511/50511 [==============================] - 6s 120us/step - loss: 0.1618 - acc: 0.7153 - auc: 0.8260 - f1: 0.7153 - val_loss: 0.1556 - val_acc: 0.7541 - val_auc: 0.8378 - val_f1: 0.7541\n",
      "Epoch 4/20\n",
      "50511/50511 [==============================] - 6s 120us/step - loss: 0.1551 - acc: 0.7361 - auc: 0.8408 - f1: 0.7361 - val_loss: 0.1452 - val_acc: 0.7473 - val_auc: 0.8606 - val_f1: 0.7473\n",
      "Epoch 5/20\n",
      "50511/50511 [==============================] - 6s 121us/step - loss: 0.1445 - acc: 0.7539 - auc: 0.8633 - f1: 0.7539 - val_loss: 0.1357 - val_acc: 0.7960 - val_auc: 0.8817 - val_f1: 0.7960\n",
      "Epoch 6/20\n",
      "50511/50511 [==============================] - 6s 120us/step - loss: 0.1315 - acc: 0.7827 - auc: 0.8876 - f1: 0.7827 - val_loss: 0.1236 - val_acc: 0.8259 - val_auc: 0.9027 - val_f1: 0.8259\n",
      "Epoch 7/20\n",
      "50511/50511 [==============================] - 6s 115us/step - loss: 0.1189 - acc: 0.8079 - auc: 0.9112 - f1: 0.8079 - val_loss: 0.1004 - val_acc: 0.8369 - val_auc: 0.9356 - val_f1: 0.8369\n",
      "Epoch 8/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1016 - acc: 0.8388 - auc: 0.9338 - f1: 0.8388 - val_loss: 0.0834 - val_acc: 0.8732 - val_auc: 0.9548 - val_f1: 0.8732\n",
      "Epoch 9/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0894 - acc: 0.8576 - auc: 0.9487 - f1: 0.8576 - val_loss: 0.0744 - val_acc: 0.8671 - val_auc: 0.9628 - val_f1: 0.8671\n",
      "Epoch 10/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0838 - acc: 0.8667 - auc: 0.9553 - f1: 0.8667 - val_loss: 0.0728 - val_acc: 0.8938 - val_auc: 0.9658 - val_f1: 0.8938\n",
      "Epoch 11/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0777 - acc: 0.8773 - auc: 0.9613 - f1: 0.8773 - val_loss: 0.0652 - val_acc: 0.8937 - val_auc: 0.9713 - val_f1: 0.8937\n",
      "Epoch 12/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0731 - acc: 0.8876 - auc: 0.9653 - f1: 0.8876 - val_loss: 0.0633 - val_acc: 0.8967 - val_auc: 0.9731 - val_f1: 0.8967\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0700 - acc: 0.8922 - auc: 0.9679 - f1: 0.8922 - val_loss: 0.0625 - val_acc: 0.9058 - val_auc: 0.9732 - val_f1: 0.9058\n",
      "Epoch 14/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0673 - acc: 0.8964 - auc: 0.9703 - f1: 0.8964 - val_loss: 0.0636 - val_acc: 0.9078 - val_auc: 0.9735 - val_f1: 0.9078\n",
      "Epoch 15/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0666 - acc: 0.8986 - auc: 0.9706 - f1: 0.8986 - val_loss: 0.0643 - val_acc: 0.9212 - val_auc: 0.9742 - val_f1: 0.9212\n",
      "Epoch 16/20\n",
      "50511/50511 [==============================] - 6s 120us/step - loss: 0.0669 - acc: 0.8974 - auc: 0.9705 - f1: 0.8974 - val_loss: 0.0576 - val_acc: 0.9200 - val_auc: 0.9775 - val_f1: 0.9200\n",
      "Epoch 17/20\n",
      "50511/50511 [==============================] - 6s 125us/step - loss: 0.0631 - acc: 0.9046 - auc: 0.9734 - f1: 0.9046 - val_loss: 0.0555 - val_acc: 0.9184 - val_auc: 0.9791 - val_f1: 0.9184\n",
      "Epoch 18/20\n",
      "50511/50511 [==============================] - 6s 125us/step - loss: 0.0617 - acc: 0.9076 - auc: 0.9745 - f1: 0.9076 - val_loss: 0.0537 - val_acc: 0.9233 - val_auc: 0.9795 - val_f1: 0.9233\n",
      "Epoch 19/20\n",
      "50511/50511 [==============================] - 6s 125us/step - loss: 0.0599 - acc: 0.9096 - auc: 0.9757 - f1: 0.9096 - val_loss: 0.0539 - val_acc: 0.9316 - val_auc: 0.9805 - val_f1: 0.9316\n",
      "Epoch 20/20\n",
      "50511/50511 [==============================] - 6s 125us/step - loss: 0.0595 - acc: 0.9105 - auc: 0.9761 - f1: 0.9105 - val_loss: 0.0507 - val_acc: 0.9269 - val_auc: 0.9821 - val_f1: 0.9269\n",
      "[[2363  119]\n",
      " [ 804 9342]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84      2482\n",
      "           1       0.99      0.92      0.95     10146\n",
      "\n",
      "    accuracy                           0.93     12628\n",
      "   macro avg       0.87      0.94      0.89     12628\n",
      "weighted avg       0.94      0.93      0.93     12628\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_70 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_71 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_72 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50511 samples, validate on 12628 samples\n",
      "Epoch 1/20\n",
      "50511/50511 [==============================] - 11s 226us/step - loss: 0.1783 - acc: 0.6962 - auc: 0.7840 - f1: 0.6962 - val_loss: 0.1608 - val_acc: 0.6910 - val_auc: 0.8299 - val_f1: 0.6910\n",
      "Epoch 2/20\n",
      "50511/50511 [==============================] - 6s 116us/step - loss: 0.1674 - acc: 0.7070 - auc: 0.8104 - f1: 0.7070 - val_loss: 0.1589 - val_acc: 0.7396 - val_auc: 0.8321 - val_f1: 0.7396\n",
      "Epoch 3/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1635 - acc: 0.7152 - auc: 0.8200 - f1: 0.7152 - val_loss: 0.1558 - val_acc: 0.7525 - val_auc: 0.8400 - val_f1: 0.7525\n",
      "Epoch 4/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1600 - acc: 0.7211 - auc: 0.8270 - f1: 0.7211 - val_loss: 0.1559 - val_acc: 0.7019 - val_auc: 0.8407 - val_f1: 0.7019\n",
      "Epoch 5/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1537 - acc: 0.7328 - auc: 0.8434 - f1: 0.7328 - val_loss: 0.1399 - val_acc: 0.7637 - val_auc: 0.8742 - val_f1: 0.7637\n",
      "Epoch 6/20\n",
      "50511/50511 [==============================] - 6s 119us/step - loss: 0.1423 - acc: 0.7612 - auc: 0.8676 - f1: 0.7612 - val_loss: 0.1263 - val_acc: 0.7776 - val_auc: 0.8981 - val_f1: 0.7776\n",
      "Epoch 7/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1302 - acc: 0.7858 - auc: 0.8903 - f1: 0.7858 - val_loss: 0.1158 - val_acc: 0.8222 - val_auc: 0.9161 - val_f1: 0.8222\n",
      "Epoch 8/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.1176 - acc: 0.8121 - auc: 0.9118 - f1: 0.8121 - val_loss: 0.0960 - val_acc: 0.8548 - val_auc: 0.9421 - val_f1: 0.8548\n",
      "Epoch 9/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0997 - acc: 0.8471 - auc: 0.9369 - f1: 0.8471 - val_loss: 0.0811 - val_acc: 0.8848 - val_auc: 0.9583 - val_f1: 0.8848\n",
      "Epoch 10/20\n",
      "50511/50511 [==============================] - 6s 117us/step - loss: 0.0865 - acc: 0.8670 - auc: 0.9521 - f1: 0.8670 - val_loss: 0.0737 - val_acc: 0.8936 - val_auc: 0.9656 - val_f1: 0.8936\n",
      "Epoch 11/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0806 - acc: 0.8753 - auc: 0.9581 - f1: 0.8753 - val_loss: 0.0685 - val_acc: 0.8879 - val_auc: 0.9690 - val_f1: 0.8879\n",
      "Epoch 12/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0761 - acc: 0.8806 - auc: 0.9625 - f1: 0.8806 - val_loss: 0.0647 - val_acc: 0.9000 - val_auc: 0.9719 - val_f1: 0.9000\n",
      "Epoch 13/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0726 - acc: 0.8861 - auc: 0.9658 - f1: 0.8861 - val_loss: 0.0640 - val_acc: 0.9076 - val_auc: 0.9728 - val_f1: 0.9076\n",
      "Epoch 14/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0698 - acc: 0.8933 - auc: 0.9685 - f1: 0.8933 - val_loss: 0.0625 - val_acc: 0.8932 - val_auc: 0.9749 - val_f1: 0.8932\n",
      "Epoch 15/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0669 - acc: 0.8973 - auc: 0.9708 - f1: 0.8973 - val_loss: 0.0565 - val_acc: 0.9220 - val_auc: 0.9781 - val_f1: 0.9220\n",
      "Epoch 16/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0637 - acc: 0.9018 - auc: 0.9729 - f1: 0.9018 - val_loss: 0.0600 - val_acc: 0.9127 - val_auc: 0.9759 - val_f1: 0.9127\n",
      "Epoch 17/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0622 - acc: 0.9053 - auc: 0.9740 - f1: 0.9053 - val_loss: 0.0604 - val_acc: 0.9172 - val_auc: 0.9770 - val_f1: 0.9172\n",
      "Epoch 18/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0623 - acc: 0.9051 - auc: 0.9743 - f1: 0.9051 - val_loss: 0.0544 - val_acc: 0.9241 - val_auc: 0.9797 - val_f1: 0.9241\n",
      "Epoch 19/20\n",
      "50511/50511 [==============================] - 6s 118us/step - loss: 0.0603 - acc: 0.9077 - auc: 0.9759 - f1: 0.9077 - val_loss: 0.0563 - val_acc: 0.9282 - val_auc: 0.9792 - val_f1: 0.9282\n",
      "Epoch 20/20\n",
      "50511/50511 [==============================] - 6s 120us/step - loss: 0.0595 - acc: 0.9104 - auc: 0.9761 - f1: 0.9104 - val_loss: 0.0562 - val_acc: 0.9165 - val_auc: 0.9784 - val_f1: 0.9165\n",
      "[[2373  109]\n",
      " [ 946 9200]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.82      2482\n",
      "           1       0.99      0.91      0.95     10146\n",
      "\n",
      "    accuracy                           0.92     12628\n",
      "   macro avg       0.85      0.93      0.88     12628\n",
      "weighted avg       0.93      0.92      0.92     12628\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_73 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_74 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_75 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50512 samples, validate on 12627 samples\n",
      "Epoch 1/20\n",
      "50512/50512 [==============================] - 12s 233us/step - loss: 0.1753 - acc: 0.6992 - auc: 0.7890 - f1: 0.6992 - val_loss: 0.1685 - val_acc: 0.6936 - val_auc: 0.8144 - val_f1: 0.6936\n",
      "Epoch 2/20\n",
      "50512/50512 [==============================] - 6s 116us/step - loss: 0.1655 - acc: 0.7125 - auc: 0.8167 - f1: 0.7125 - val_loss: 0.1615 - val_acc: 0.7387 - val_auc: 0.8238 - val_f1: 0.7387\n",
      "Epoch 3/20\n",
      "50512/50512 [==============================] - 6s 117us/step - loss: 0.1611 - acc: 0.7195 - auc: 0.8247 - f1: 0.7195 - val_loss: 0.1625 - val_acc: 0.7413 - val_auc: 0.8262 - val_f1: 0.7413\n",
      "Epoch 4/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.1564 - acc: 0.7276 - auc: 0.8364 - f1: 0.7276 - val_loss: 0.1528 - val_acc: 0.7352 - val_auc: 0.8466 - val_f1: 0.7352\n",
      "Epoch 5/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.1437 - acc: 0.7585 - auc: 0.8650 - f1: 0.7585 - val_loss: 0.1351 - val_acc: 0.7440 - val_auc: 0.8861 - val_f1: 0.7440\n",
      "Epoch 6/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.1295 - acc: 0.7838 - auc: 0.8935 - f1: 0.7838 - val_loss: 0.1142 - val_acc: 0.8457 - val_auc: 0.9209 - val_f1: 0.8457\n",
      "Epoch 7/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.1136 - acc: 0.8203 - auc: 0.9194 - f1: 0.8203 - val_loss: 0.0981 - val_acc: 0.8338 - val_auc: 0.9390 - val_f1: 0.8338\n",
      "Epoch 8/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.0982 - acc: 0.8468 - auc: 0.9396 - f1: 0.8468 - val_loss: 0.0888 - val_acc: 0.8883 - val_auc: 0.9541 - val_f1: 0.8883\n",
      "Epoch 9/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.0894 - acc: 0.8633 - auc: 0.9496 - f1: 0.8633 - val_loss: 0.0778 - val_acc: 0.9001 - val_auc: 0.9635 - val_f1: 0.9001\n",
      "Epoch 10/20\n",
      "50512/50512 [==============================] - 6s 117us/step - loss: 0.0828 - acc: 0.8733 - auc: 0.9561 - f1: 0.8733 - val_loss: 0.0726 - val_acc: 0.8983 - val_auc: 0.9672 - val_f1: 0.8983\n",
      "Epoch 11/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.0773 - acc: 0.8825 - auc: 0.9617 - f1: 0.8825 - val_loss: 0.0650 - val_acc: 0.9047 - val_auc: 0.9724 - val_f1: 0.9047\n",
      "Epoch 12/20\n",
      "50512/50512 [==============================] - 6s 121us/step - loss: 0.0735 - acc: 0.8878 - auc: 0.9649 - f1: 0.8878 - val_loss: 0.0629 - val_acc: 0.8970 - val_auc: 0.9732 - val_f1: 0.8970\n",
      "Epoch 13/20\n",
      "50512/50512 [==============================] - 7s 129us/step - loss: 0.0693 - acc: 0.8931 - auc: 0.9683 - f1: 0.8931 - val_loss: 0.0636 - val_acc: 0.9146 - val_auc: 0.9745 - val_f1: 0.9146\n",
      "Epoch 14/20\n",
      "50512/50512 [==============================] - 6s 128us/step - loss: 0.0676 - acc: 0.8976 - auc: 0.9701 - f1: 0.8976 - val_loss: 0.0598 - val_acc: 0.9149 - val_auc: 0.9764 - val_f1: 0.9149\n",
      "Epoch 15/20\n",
      "50512/50512 [==============================] - 6s 129us/step - loss: 0.0652 - acc: 0.9032 - auc: 0.9722 - f1: 0.9032 - val_loss: 0.0571 - val_acc: 0.9233 - val_auc: 0.9785 - val_f1: 0.9233\n",
      "Epoch 16/20\n",
      "50512/50512 [==============================] - 6s 120us/step - loss: 0.0647 - acc: 0.9018 - auc: 0.9724 - f1: 0.9018 - val_loss: 0.0559 - val_acc: 0.9211 - val_auc: 0.9791 - val_f1: 0.9211\n",
      "Epoch 17/20\n",
      "50512/50512 [==============================] - 6s 115us/step - loss: 0.0620 - acc: 0.9068 - auc: 0.9745 - f1: 0.9068 - val_loss: 0.0590 - val_acc: 0.9159 - val_auc: 0.9772 - val_f1: 0.9159\n",
      "Epoch 18/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.0630 - acc: 0.9046 - auc: 0.9737 - f1: 0.9046 - val_loss: 0.0549 - val_acc: 0.9274 - val_auc: 0.9800 - val_f1: 0.9274\n",
      "Epoch 19/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.0613 - acc: 0.9103 - auc: 0.9751 - f1: 0.9103 - val_loss: 0.0593 - val_acc: 0.9236 - val_auc: 0.9772 - val_f1: 0.9236\n",
      "Epoch 20/20\n",
      "50512/50512 [==============================] - 6s 118us/step - loss: 0.0594 - acc: 0.9115 - auc: 0.9766 - f1: 0.9115 - val_loss: 0.0537 - val_acc: 0.9192 - val_auc: 0.9803 - val_f1: 0.9192\n",
      "[[2353  129]\n",
      " [ 891 9254]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82      2482\n",
      "           1       0.99      0.91      0.95     10145\n",
      "\n",
      "    accuracy                           0.92     12627\n",
      "   macro avg       0.86      0.93      0.88     12627\n",
      "weighted avg       0.93      0.92      0.92     12627\n",
      "\n",
      "time (in seconds) 645.7026228904724\n",
      "... DONE!\n",
      "... DONE!\n"
     ]
    }
   ],
   "source": [
    "listResults = {} \n",
    "for i in [2, 3, 4, 5, 6]:\n",
    "    print(\"window_size: \"+str(i))\n",
    "    listResults[i] = applyTensor(i, df)\n",
    "    print(\"... DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FROM WINDOW SIZE 2\n",
      "[[ 6040   593]\n",
      " [ 2899 26088]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78      6633\n",
      "           1       0.98      0.90      0.94     28987\n",
      "\n",
      "    accuracy                           0.90     35620\n",
      "   macro avg       0.83      0.91      0.86     35620\n",
      "weighted avg       0.92      0.90      0.91     35620\n",
      "\n",
      "ROC_AUC: 0.9052940865359024\n",
      "F1-Score: 0.9047890461243041\n",
      "Precision: 0.9096399038442895\n",
      "Recall: 0.8999896505329887\n",
      "Accuracy: 0.9052940865359091\n",
      "Time in seconds: 309.37557673454285\n",
      "\n",
      "\n",
      "RESULTS FROM WINDOW SIZE 3\n",
      "[[ 5905   286]\n",
      " [ 2890 24172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.95      0.79      6191\n",
      "           1       0.99      0.89      0.94     27062\n",
      "\n",
      "    accuracy                           0.90     33253\n",
      "   macro avg       0.83      0.92      0.86     33253\n",
      "weighted avg       0.93      0.90      0.91     33253\n",
      "\n",
      "ROC_AUC: 0.9235060487518971\n",
      "F1-Score: 0.9211160333627543\n",
      "Precision: 0.9508240572263194\n",
      "Recall: 0.8932081886037775\n",
      "Accuracy: 0.9235060487519808\n",
      "Time in seconds: 408.2010519504547\n",
      "\n",
      "\n",
      "RESULTS FROM WINDOW SIZE 4\n",
      "[[ 5500   349]\n",
      " [ 2418 22749]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.94      0.80      5849\n",
      "           1       0.98      0.90      0.94     25167\n",
      "\n",
      "    accuracy                           0.91     31016\n",
      "   macro avg       0.84      0.92      0.87     31016\n",
      "weighted avg       0.93      0.91      0.92     31016\n",
      "\n",
      "ROC_AUC: 0.9221267414945986\n",
      "F1-Score: 0.9206827762641141\n",
      "Precision: 0.9380770744476313\n",
      "Recall: 0.9039218023600338\n",
      "Accuracy: 0.9221267414947004\n",
      "Time in seconds: 505.87783455848694\n",
      "\n",
      "\n",
      "RESULTS FROM WINDOW SIZE 5\n",
      "[[ 5499   357]\n",
      " [ 1528 21568]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      5856\n",
      "           1       0.98      0.93      0.96     23096\n",
      "\n",
      "    accuracy                           0.93     28952\n",
      "   macro avg       0.88      0.94      0.91     28952\n",
      "weighted avg       0.94      0.93      0.94     28952\n",
      "\n",
      "ROC_AUC: 0.9364391215283705\n",
      "F1-Score: 0.9362735753345321\n",
      "Precision: 0.9387184955080566\n",
      "Recall: 0.9338413578108457\n",
      "Accuracy: 0.9364391215283893\n",
      "Time in seconds: 575.0116217136383\n",
      "\n",
      "\n",
      "RESULTS FROM WINDOW SIZE 6\n",
      "[[ 4956   293]\n",
      " [ 1826 19985]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.94      0.82      5249\n",
      "           1       0.99      0.92      0.95     21811\n",
      "\n",
      "    accuracy                           0.92     27060\n",
      "   macro avg       0.86      0.93      0.89     27060\n",
      "weighted avg       0.94      0.92      0.93     27060\n",
      "\n",
      "ROC_AUC: 0.9302303097675572\n",
      "F1-Score: 0.9292432865872213\n",
      "Precision: 0.9425778184300501\n",
      "Recall: 0.9162807757553499\n",
      "Accuracy: 0.93023030976756\n",
      "Time in seconds: 645.7026228904724\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [2, 3, 4, 5, 6]:\n",
    "    print(\"RESULTS FROM WINDOW SIZE\",i)\n",
    "    lastModel = listResults[i][0]\n",
    "    history_general = listResults[i][1]\n",
    "    X_test = listResults[i][2]\n",
    "    y_test = listResults[i][3]\n",
    "    time_in_seconds = listResults[i][4]\n",
    "\n",
    "    fractions_t = 1-y_test.sum(axis=0)/len(y_test)\n",
    "    weights_t = fractions_t[y_test.argmax(axis=1)]\n",
    "\n",
    "    output = lastModel.predict_classes(X_test)\n",
    "    print(confusion_matrix(y_test.argmax(axis=1), output))\n",
    "    print(classification_report(y_test.argmax(axis=1), output))\n",
    "    evaluation_metrics(y_test.argmax(axis=1), output, weights_t)\n",
    "    print(\"Time in seconds:\", time_in_seconds)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
